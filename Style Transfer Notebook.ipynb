{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install fse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pytorch-nlp","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"033cb94d-2872-47fb-b6d9-cfca0ea6ebdc","_cell_guid":"39c9303e-2110-4d17-811c-cf17fb86f691","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport re\nimport string \nimport collections\nimport fse\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchnlp.metrics import get_moses_multi_bleu\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(1)\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"215a6bb9-71c2-4fbf-833e-62164e58ae24","_cell_guid":"f34b7975-7e56-49ce-8669-2b29e486ebbd","trusted":true},"cell_type":"markdown","source":"# Data Pre-Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#yelp\nroot = \"../input/style-transfer-dataset/yelp/\"\n\nd_pos_path = root+\"sentiment.train.1\"\nd_neg_path = root+\"sentiment.train.0\"\n\n#Problem: Data imbalance? -> decoder might be biased towards positive\nd_pos = pd.read_csv(d_pos_path, sep=\"\\n\", header=None)#.iloc[:,0]\nd_neg = pd.read_csv(d_neg_path, sep=\"\\n\", header=None)#.iloc[:,0]\nd_both = pd.concat((d_pos, d_neg), ignore_index=True)\n\n#Problem: Data imbalance? -> decoder might be biased towards positive\nd_pos = pd.read_csv(d_pos_path, sep=\"\\n\", header=None)#.iloc[:,0]\nd_neg = pd.read_csv(d_neg_path, sep=\"\\n\", header=None)#.iloc[:,0]\nd_both = pd.concat((d_pos, d_neg), ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_labels = pd.DataFrame(np.concatenate( ( np.ones((d_pos.size, 1)), np.zeros((d_neg.size, 1)) ) ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_all = pd.concat((d_pos, d_neg), ignore_index=True)\nd_all['labels'] = d_labels\nd_all.columns = ['text', 'labels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = d_all.columns.tolist()\ncols = cols[-1:] + cols[:-1]\nd_all = d_all[cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_pos=d_pos.iloc[:,0]\nd_neg=d_neg.iloc[:,0]\nd_both=d_both.iloc[:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_pos_ref_path = root+\"reference.1\"\nd_pos_ref = []\nd_pos_ref_file = open(d_pos_ref_path, 'r')\nfor line in d_pos_ref_file.readlines():\n    pair = line.split(\"\\t\")\n    pair[1] = ' '.join(re.findall(r\"\\w+|[^\\w\\s]\", pair[1], re.UNICODE))  #split punctuation\n    d_pos_ref.append(pair)\n    \nd_neg_ref_path = root+\"reference.0\"\nd_neg_ref = []\nd_neg_ref_file = open(d_neg_ref_path, 'r')\nfor line in d_neg_ref_file.readlines():\n    pair = line.split(\"\\t\")\n    pair[1] = ' '.join(re.findall(r\"\\w+|[^\\w\\s]\", pair[1], re.UNICODE))  #split punctuation\n    d_neg_ref.append(pair)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf22d0c8-c397-450f-821d-17c8e439ee85","_cell_guid":"1258b67e-c902-4662-8774-b720d3ca5c59","trusted":true},"cell_type":"markdown","source":"# Components\n\n### Content & Attributes Separation"},{"metadata":{"_uuid":"2611f10a-e71c-4524-aaeb-7308b6e809ac","_cell_guid":"c901b518-b9d0-4bc0-8e9f-943fa4ad93ec","trusted":true},"cell_type":"code","source":"#Parameters:\nparam_smooth = 1\nparam_threshold = 15\nparam_span = 4\n\nparam_backoff_limit = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ngram has punctuation\ndef has_punctuation(ngram): #damn I'm very proud of making this from scratch lol, looks elegant in one line\n    return True in [x in string.punctuation for x in ngram]\n\ndef generate_ngrams(lines, min_length=1, max_length=param_span):\n#     lines = placeholder + lines\n    lengths = range(min_length, max_length + 1)\n    ngrams = {length: [] for length in lengths}\n    queue = collections.deque(maxlen=max_length)\n    \n    def add_queue():\n        current = tuple(queue)\n        for length in lengths:\n            if len(current) >= length and not has_punctuation(current[:length]):\n                ngrams[length].append(current[:length])\n    \n    short_by = 0\n    for line in lines:\n        short_by = max(0, max_length - len(lines))\n        for word in line.split():\n            queue.append(word)\n            if len(queue) >= max_length-short_by:\n                add_queue()                \n\n    while len(queue) > min_length:\n        queue.popleft()\n        add_queue()\n    return ngrams\n\n#modified from & fixed their error of ngram with # of words < 4: https://gist.github.com/benhoyt/dfafeab26d7c02a52ed17b6229f0cb52\ndef count_ngrams(lines, min_length=1, max_length=param_span):\n    \"\"\"Iterate through given lines iterator (file object or list of\n    lines) and return n-gram frequencies. The return value is a dict\n    mapping the length of the n-gram to a collections.Counter\n    object of n-gram tuple and number of times that n-gram occurred.\n    Returned dict includes n-grams of length min_length to max_length.\n    \"\"\"\n    lengths = range(min_length, max_length + 1)\n    ngrams = {length: collections.Counter() for length in lengths}\n    queue = collections.deque(maxlen=max_length)\n\n    # Helper function to add n-grams at start of current queue to dict\n    def add_queue():\n        current = tuple(queue)\n        for length in lengths:\n            if len(current) >= length and not has_punctuation(current[:length]):\n                ngrams[length][current[:length]] += 1\n\n    # Loop through all lines and words and add n-grams to dict\n    short_by = 0\n    for line in lines:\n        short_by = max(0, max_length - len(lines))\n        for word in line.split():\n            queue.append(word)\n            if len(queue) >= max_length - short_by:\n                add_queue()\n\n    # Make sure we get the n-grams at the tail end of the queue\n    while len(queue) > min_length:\n        queue.popleft()\n        add_queue()\n\n    return ngrams\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generate ngram counts for d_pos & d_neg\nd_pos_ngrams_counts = count_ngrams(d_pos.tolist())\nd_neg_ngrams_counts = count_ngrams(d_neg.tolist())\n\ndef get_counts(list1, counted_ngrams):\n    counts = []\n    list1_ngrams = generate_ngrams(list1)\n    list2_counts = counted_ngrams\n    \n    for length in range(param_span,0, -1):\n        for v in list1_ngrams[length]:\n            counts.append([list2_counts[length][v], v])\n    return np.array(counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#these are methods that will become useful when extracting attribute markers\n#why do we need all this? well... that's like 5 hours of debugging...\ndef flatten(foo):\n    return list(_flatten(foo))\n\ndef _flatten(foo):\n    for x in foo:\n        if isinstance(x, collections.Iterable) and not isinstance(x, str):\n            for y in _flatten(x):\n                yield y\n        else:\n            yield x\n# def is_in_string_array(elements, original):\n#     return ' '.join(flatten(elements)) in ' '.join(flatten(original)) \n\ndef array_to_string(a):\n    return ' '.join(flatten(a))\n\n#TODO: pretty hackery stuff, doesn't work if it's like \"really slow\" then repeated but wait a minute hmmm ya how do you account for repeats\ndef is_in_string_array(elements, original): #deprecated, does not take into account sequence order\n#     print(array_to_string(elements).split(), array_to_string(original).split())\n#     print(np.isin(array_to_string(elements).split(), array_to_string(original).split()))\n    return np.isin(array_to_string(elements).split(), array_to_string(original).split()).any()\n#      return np.isin(array_to_string(), flatten(np.array(original))).all()\n\ndef insert_string(string, inserted_string, index):\n    return string[:index] + inserted_string + string[index:]\n\n# def is_in_array(elements, original): #deprecated, does not take into account sequence order\n#     return np.isin(elements, original).all()\n\n# modified from https://stackoverflow.com/questions/41752946/replacing-a-character-from-a-certain-index\ndef replace_string(s, newstring, index, nofail=False):\n    # raise an error if index is outside of the string\n    if not nofail and index not in range(len(s)):\n        raise ValueError(\"index outside given string. index:\" + index)\n\n    # if not erroring, but the index is still not in the correct range..\n    if index < 0:  # add it to the beginning\n        return newstring + s\n    if index > len(s):  # add it to the end\n        return s + newstring\n\n    # insert the new string between \"slices\" of the original\n    return s[:index] + newstring + s[index + len(newstring):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# did some really hacky stuff here & above yesterday coding\n# while having a headache & sick lol. it'd take a long time\n# tocomprehend again what exactly this code means again,\n# will clean it up eventually...\n\n\ndef get_attribute_markers(s, style_src):\n    sentence = [s]\n    \n    ngrams = get_counts(sentence, d_pos_ngrams_counts)\n    if len(ngrams) > 0:\n        ngrams = ngrams[:,1]\n    \n    pos_counts = get_counts(sentence, d_pos_ngrams_counts)\n    if len(pos_counts) > 0:\n        pos_counts = pos_counts[:,0]\n    \n    neg_counts = get_counts(sentence, d_neg_ngrams_counts)\n    if len(neg_counts) > 0:\n        neg_counts = neg_counts[:,0]\n    \n    \n    if(style_src):\n        importances = (pos_counts + param_smooth) / (neg_counts + param_smooth)\n    else:\n        importances = (neg_counts + param_smooth) / (pos_counts + param_smooth)\n        \n    a = []\n    \n    importances = np.vstack((importances, ngrams)).T\n    for importance in importances:\n#         print(np.array(a).flatten(), importance[1])\n        if importance[0] > param_threshold and not is_in_string_array(importance[1], a): # and importance[0] > highest[0]:\n            a.append(' '.join(importance[1]))\n#             a = np.insert(a, 0, importance[1], axis=0)\n    return a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def separate(sentence, style_src):\n#     try:\n    attributes = get_attribute_markers(sentence, style_src)\n    #if a empty use this try thing\n#         a = a\n    c = sentence\n\n    replace_indexes = []\n    for a in attributes:\n        replace_index = -1\n        replace_index = c.find(a)\n        replace_indexes.append(replace_index)\n        c = c.replace(a, \" \"*len(a))\n    #TODO: templatebased insert string back\n# insert_string(c, a, replace_index)\n\n    # quick hack to sort: https://stackoverflow.com/questions/9764298/is-it-possible-to-sort-two-listswhich-reference-each-other-in-the-exact-same-w\n    \n    #TODO: prevent error when len(attributes) = 0\n    if len(attributes) == 0:\n        return {'c': c, 'a': [], 'i': [], 's': sentence}\n    \n    replace_indexes, attributes = zip(*sorted(zip(replace_indexes, attributes)))\n    return {'c': c, 'a': attributes, 'i': replace_indexes, 's': sentence}\n#     except:\n#         #TODO: maybe add one after len(c)?\n#         return {'c': sentence, 'a': \"\", 'i': len(sentence), 's': sentence}\n\ndef get_c(sentence, style):\n    return re.sub(' +', ' ', separate(sentence, style)['c'])\n\ndef get_a(sentence, style):\n    a = separate(sentence, style)['a']\n    if len(a) > 0:\n        return ' '.join(a)\n    else:\n        return \"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TF-IDF Distance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ===== Euclidean distance ===== #\n# get content embeddings by using RNN. First train it in DeleteOnly\n\n\n\n# ===== TF-IDF Weighted Word Overlap ===== #\n# docs pre-processing\ndocs = d_both.tolist()\n\n# creating dict_idf = {word: idf}\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vectorizer=TfidfVectorizer(use_idf=True, stop_words=None)\ntfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(docs)\ndict_idf = dict(zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer.idf_))\n\ndef get_overlap(a, b):\n#     print(a, b)\n    a_counter = collections.Counter(a.split())\n    b_counter = collections.Counter(b.split())\n    overlap = a_counter & b_counter\n    return overlap\n\ndef get_weighted_overlap(a, b):\n    overlap = get_overlap(a, b)\n    a_counter = collections.Counter(a.split())\n    #calculate\n    weighted_overlap = 0\n    for word in overlap:\n\n        word_tf = a_counter[word]#/len(a.split()) -> commented out cause division by constant value doesn't matter\n\n        get_idf = dict_idf.get(word)\n        word_idf = 1 if get_idf == None else get_idf #get rid of error when idf not in dict \n\n        word_tfidf = word_tf*word_idf\n        weighted_overlap+=overlap[word]*word_tfidf\n\n    return weighted_overlap\n\ndef get_closest_sentence_tfidf(sentence, style_src):\n    opposite_dataset = d_neg if style_src else d_pos\n\n    highest_overlap = 0\n    closest_sentence = \"\"\n    \n    min_attribute_markers=len(get_attribute_markers(sentence, style_src))\n    num_markers = 0\n    \n    previous_sentences = []\n    backoff_count = 0\n    while(num_markers < min_attribute_markers and backoff_count < param_backoff_limit):\n        for sentence_b in opposite_dataset:\n            weighted_overlap = get_weighted_overlap(sentence, sentence_b)\n            if weighted_overlap > highest_overlap and sentence_b not in previous_sentences:\n#                 print(\"===\")\n#                 print(closest_sentence)\n#                 print(sentence_b)\n#                 print(closest_sentence!=sentence_b)\n#                 print(\"===\")\n                highest_overlap = weighted_overlap\n                closest_sentence = sentence_b\n        highest_overlap = 0 \n        backoff_count += 1\n        previous_sentences.append(closest_sentence)\n#         print(closest_sentence)\n#         print(get_attribute_markers(closest_sentence, not style_src))\n        num_markers = len(get_attribute_markers(closest_sentence, not style_src))\n    \n    return closest_sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Retrieve using tfidf\ndef retrieve(sentence, style_src):\n    #Todo: implement euclidian distance\n    return separate(get_closest_sentence_tfidf(sentence, style_src), not style_src)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Template Based"},{"metadata":{"trusted":true},"cell_type":"code","source":"def insert_multi(s, indexes):\n    d = {\n        'w1': {'begin':'0', 'end':'3', 'w':'BIG'},\n        'w2': {'being':'7', 'end':'7', 'w':'BARKED'}\n    }\n    \n    \n    final_s = re.sub('|'.join('\\{}'.format(s[int(b['end'])]) for _, b in d.items()), \"{}\", s).format(*[c['w'] for _, c in sorted(d.items(), key=lambda x:int(x[0][-1]))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def TemplateBased(sentence, style_src):\n    \n    separated_src = separate(sentence, style_src)\n    c_src = separated_src['c']\n    replace_indexes = separated_src['i']\n    \n    separated_tgt = retrieve(sentence, style_src)\n    a_tgt = separated_tgt['a']\n    \n    #DEBUG\n#     print(separated_src)\n#     print(separated_tgt)\n    \n    missing_attributes =len(replace_indexes) - len(a_tgt)\n    \n    if len(a_tgt) > 0:\n        for i in range(missing_attributes):\n            a_tgt += (a_tgt[0],) #TODO: rn adds placeholder in case of not enough attributes    -> (\"placeholder\",)\n    \n    output = c_src\n\n    #deprecated insertion, now uses replace\n    #loops backwards as by inserting backwards, you don't need to take into account the increasing length \n#     for i in range(len(replace_indexes)-1, -1, -1):\n#         output = insert_string(output, a_tgt[i]+\" \", replace_indexes[i])\n\n#     #replace\n#     for i in range(len(replace_indexes)):\n#         if replace_indexes[i] >= 0\n#             output = replace_string(output, a_tgt[i], replace_indexes[i])\n\n    #NEW hackery way: insert back to front, then split & join -> to account of tgt attribute length > src attribute\n    for i in range(len(replace_indexes)-1, -1, -1):\n        if i < len(a_tgt):\n            output = insert_string(output, a_tgt[i]+\" \", replace_indexes[i])\n    \n    output = ' '.join(output.split())\n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sentence = d_pos[2]#\"we sit down and we got some really slow and lazy service .\"# #positive\nsentence = \"we got down and we got some really slow and lazy service .\" #repeats don't work\nstyle_src = 0\nTemplateBased(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{},"cell_type":"markdown","source":"### DeleteAndRetrieve"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resources: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n# Had to modify & adapt most of the code in the tutorial since this isn't translation & data preprocessing is different\n\nSOS_token = 0\nEOS_token = 1\n\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_total_overlap(a, b):\n    return len(list(get_overlap(a, b).elements()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"noise_chance = 0.1\n\ndef prepareData():\n    input_lang = Lang(\"input\")\n    output_lang = Lang(\"output\")\n    \n    d_pos_a = []\n    \n    pairs_pos = []\n    for sentence in d_pos:\n        c = get_c(sentence, 1)\n        a = get_a(sentence, 1)\n        d_pos_a.append(a)\n        pairs_pos.append([c, a, sentence])\n    \n    d_neg_a = []\n    \n    pairs_neg = []\n    for sentence in d_neg:\n        c = get_c(sentence, 0)\n        a = get_a(sentence, 0)\n        d_neg_a.append(a)\n        pairs_neg.append([c, a, sentence])\n    \n    #adding noise for pos\n    for pair in pairs_pos:\n        if random.random() < noise_chance:\n            real_a = pair[1].split()\n            #problem: what to do when there's no attribute markers?\n            if(len(real_a) == 0):\n                continue\n\n            for a in d_pos_a:\n                if(len(a) == 0):\n                    continue\n                a = a.split()\n\n                overlap = get_total_overlap(' '.join(real_a), ' '.join(a))\n                if overlap > 0 and ((overlap == len(real_a) - 1 and len(real_a) - len(a) == 1) or (overlap == len(real_a) and len(real_a) - len(a) == -1)):\n                    #problem: order???\n                    #Debug\n#                     print(\"real_a -> a :\", real_a, '->', a)\n#                     print(\"overlap: \", overlap)\n#                     print()\n#                     print(\"====\")\n\n\n                    real_a = a\n                    break;\n            pair[1] = ' '.join(real_a)\n    \n    \n    #adding noise for neg\n    for pair in pairs_neg:\n        if random.random() < noise_chance:\n            real_a = pair[1].split()\n            if(len(real_a) == 0):\n                continue\n\n            for a in d_neg_a:\n                if(len(a) == 0):\n                    continue\n                a = a.split()\n\n                overlap = get_total_overlap(' '.join(real_a), ' '.join(a))\n                if overlap > 0 and ((overlap == len(real_a) - 1 and len(real_a) - len(a) == 1) or (overlap == len(real_a) and len(real_a) - len(a) == -1)):\n                    #problem: order???\n                    #Debug\n#                     print(\"real_a -> a :\", real_a, '->', a)\n\n\n                    real_a = a\n                    break;\n            pair[1] = ' '.join(real_a)\n\n            \n    pairs = np.concatenate((pairs_pos, pairs_neg), 0)\n    #TODO: Check that this concatenation works\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        input_lang.addSentence(pair[1])\n        output_lang.addSentence(pair[2])\n        \n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_lang, output_lang, pairs = prepareData()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for pair in d_pos_ref:\n    input_lang.addSentence(pair[0])\n    output_lang.addSentence(pair[1])\nfor pair in d_neg_ref:\n    input_lang.addSentence(pair[0])\n    output_lang.addSentence(pair[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Maxout(nn.Module):\n    def __init__(self, pool_size):\n        super().__init__()\n        self._pool_size = pool_size\n\n    def forward(self, x):\n        assert x.shape[1] % self._pool_size == 0, \\\n            'Wrong input last dim size ({}) for Maxout({})'.format(x.shape[1], self._pool_size)\n        m, i = x.view(*x.shape[:1], x.shape[1] // self._pool_size, self._pool_size, *x.shape[2:]).max(2)\n        return m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, word_vec_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        \n        self.embedding = nn.Embedding(input_size, word_vec_size)\n        self.gru = nn.GRU(word_vec_size, hidden_size)\n\n    def forward(self, input, hidden):\n        embedded = self.embedding(input).view(1, 1, -1)\n        output = embedded\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, word_vec_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.embedding = nn.Embedding(output_size, word_vec_size)\n        self.gru = nn.GRU(word_vec_size, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n        self.maxout = Maxout(1)\n\n    def forward(self, input, hidden):\n        output = self.embedding(input).view(1, 1, -1)\n        output = self.maxout(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Preparing Training Data\ndef indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\n\ndef tensorsFromPair(pair):\n    input_c_tensor = tensorFromSentence(input_lang, pair[0])\n    input_a_tensor = tensorFromSentence(input_lang, pair[1])\n    target_tensor = tensorFromSentence(output_lang, pair[2])\n    return (input_c_tensor, input_a_tensor, target_tensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training\nMAX_LENGTH = 50\n\nteacher_forcing_ratio = 0.5\n\n\ndef train(input_c_tensor, input_a_tensor, target_tensor, encoder_c, encoder_a, decoder, encoder_c_optimizer, encoder_a_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n    encoder_c_hidden = encoder_c.initHidden()\n    encoder_a_hidden = encoder_a.initHidden()\n\n    encoder_a_optimizer.zero_grad()\n    encoder_c_optimizer.zero_grad()\n\n    decoder_optimizer.zero_grad()\n\n    input_c_length = input_c_tensor.size(0)\n    input_a_length = input_a_tensor.size(0)\n    \n    target_length = target_tensor.size(0)\n\n    encoder_c_outputs = torch.zeros(max_length, encoder_c.hidden_size, device=device)\n    encoder_a_outputs = torch.zeros(max_length, encoder_a.hidden_size, device=device)\n    \n    loss = 0\n\n    for ei in range(input_c_length):\n        encoder_c_output, encoder_c_hidden = encoder_c(\n            input_c_tensor[ei], encoder_c_hidden)\n        encoder_c_outputs[ei] = encoder_c_output[0, 0]\n    \n    for ei in range(input_a_length):\n        encoder_a_output, encoder_a_hidden = encoder_a(\n            input_a_tensor[ei], encoder_a_hidden)\n        encoder_a_outputs[ei] = encoder_a_output[0, 0]\n\n    \n    decoder_input = torch.tensor([[SOS_token]], device=device)\n\n#     decoder_hidden = encoder_c_hidden\n    \n    decoder_hidden = torch.cat((encoder_c_hidden, encoder_a_hidden), 2)\n    \n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if use_teacher_forcing:\n        # Teacher forcing: Feed the target as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden)\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]  # Teacher forcing\n\n    else:\n        # Without teacher forcing: use its own predictions as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden)\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # detach from history as input\n\n            loss += criterion(decoder_output, target_tensor[di])\n            if decoder_input.item() == EOS_token:\n                break\n\n    loss.backward()\n    \n    encoder_c_optimizer.step()\n    encoder_a_optimizer.step()\n    decoder_optimizer.step()\n\n    return loss.item() / target_length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport math\n#(input_c_tensor, input_a_tensor, target_tensor)\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def trainIters(encoder_a, encoder_c, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n    \n    encoder_c_optimizer = optim.Adadelta(encoder_c.parameters(), lr=learning_rate)\n    encoder_a_optimizer = optim.Adadelta(encoder_a.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adadelta(decoder.parameters(), lr=learning_rate)\n    training_pairs = [tensorsFromPair(random.choice(pairs))\n                      for i in range(n_iters)]\n    criterion = nn.NLLLoss()\n\n    for iter in range(1, n_iters + 1):\n        training_pair = training_pairs[iter - 1]\n        input_a_tensor = training_pair[0]\n        input_c_tensor = training_pair[1]\n        \n        #todo\n        target_tensor = training_pair[2]\n        #input_c_tensor, input_a_tensor, target_tensor, encoder_c, encoder_a, decoder, encoder_c_optimizer, encoder_a_optimizer, decoder_optimizer\n        loss = train(input_c_tensor, input_a_tensor, target_tensor, encoder_c, encoder_a,\n                     decoder, encoder_c_optimizer, encoder_c_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if iter % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n                                         iter, iter / n_iters * 100, print_loss_avg))\n\n        if iter % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_vec_size = 128\nhidden_size = 512\nencoder_c = EncoderRNN(input_lang.n_words, word_vec_size, hidden_size).to(device)\nencoder_a = EncoderRNN(input_lang.n_words, word_vec_size, hidden_size).to(device)\n\ndecoder = DecoderRNN(hidden_size + hidden_size, word_vec_size, output_lang.n_words).to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainIters(encoder_c, encoder_a, decoder, 200000, print_every=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encoderStep(encoder_c, encoder_a, c, a, max_length=MAX_LENGTH):\n    input_c_tensor = tensorFromSentence(input_lang, c)\n    input_a_tensor = tensorFromSentence(input_lang, a)\n\n    input_c_length = input_c_tensor.size()[0]\n    input_a_length = input_a_tensor.size()[0]\n\n    encoder_c_hidden = encoder_c.initHidden()\n    encoder_a_hidden = encoder_a.initHidden()\n\n    encoder_c_outputs = torch.zeros(max_length, encoder_c.hidden_size, device=device)\n    encoder_a_outputs = torch.zeros(max_length, encoder_a.hidden_size, device=device)\n    \n    for ei in range(input_c_length):\n        encoder_c_output, encoder_c_hidden = encoder_c(input_c_tensor[ei],\n                                                 encoder_c_hidden)\n        encoder_c_outputs[ei] += encoder_c_output[0, 0]\n\n\n    for ei in range(input_a_length):\n        encoder_a_output, encoder_a_hidden = encoder_a(input_a_tensor[ei],\n                                                 encoder_a_hidden)\n        encoder_a_outputs[ei] += encoder_a_output[0, 0]\n    \n\n    \n    return torch.cat((encoder_c_hidden, encoder_a_hidden), 2)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_c_embedding(encoder_c, c, max_length=MAX_LENGTH):\n    input_c_tensor = tensorFromSentence(input_lang, c)\n    \n    input_c_length = input_c_tensor.size()[0]\n\n    encoder_c_hidden = encoder_c.initHidden()\n\n    encoder_c_outputs = torch.zeros(max_length, encoder_c.hidden_size, device=device)\n    \n    for ei in range(input_c_length):\n        encoder_c_output, encoder_c_hidden = encoder_c(input_c_tensor[ei],\n                                                 encoder_c_hidden)\n        encoder_c_outputs[ei] += encoder_c_output[0, 0]\n        \n    return encoder_c_hidden\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ALPHA = 0.7\n\nclass Node:\n    def __init__(self, p_t, i, d_hidden, lvl, node_parent=None):\n        self.p_t = p_t\n        self.i = i\n        self.d_hidden = d_hidden\n        self.lvl = lvl\n        self.node_parent = node_parent\n        \n        self.p_sentence = self.sentenceProb()\n    \n    def prepareToDecode(self):\n        d_in = self.i.squeeze()#.detatch()\n        return d_in, self.d_hidden\n    \n    def sentenceProb(self):\n        if self.node_parent == None:\n            return self.p_t\n        return self.node_parent.sentenceProb() + self.p_t #addition because of log\n    \n    def normProb(self):\n        #Normalised probability\n#         return 1/((self.lvl+1)**ALPHA) * self.sentenceProb()\n        #perplexity\n        return torch.exp(self.sentenceProb()) ** (-1/(self.lvl+1))\n    \n    def getToken(self):\n        return output_lang.index2word[self.i.item()]\n    \n    def getTokens(self):\n        token = [self.getToken()]\n#         print(token)\n        if(self.node_parent == None):\n            return token\n        else:\n             return self.node_parent.getTokens() + token\n#         return tokens\n    def getSentence(self):\n        return ' '.join(self.getTokens())\n# Normalize 1/num words^alpha (alpha = 0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#input_c_tensor, input_a_tensor, target_tensor, encoder_c, encoder_a, decoder, encoder_c_optimizer, encoder_a_optimizer, decoder_optimizer\nBEAM_WIDTH = 10\n\ndef evaluate(encoder_c, encoder_a, decoder, c, a, max_length=MAX_LENGTH):\n    with torch.no_grad():    \n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoderStep(encoder_c, encoder_a, c, a)\n        decoded_words = []\n        \n        \n        \n        \n        #TODO: BEAM SEARCH\n        \n        nodes = []\n        finished_nodes = []\n        for di in range(max_length):\n            if di == 0:\n                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n                top_ps, top_is = decoder_output.data.topk(BEAM_WIDTH)\n    #             print(topv, topi)\n    #             print(decoder_output.data.topk(10))\n    #             print(topv, topi.item(), output_lang.index2word[topi.item()])\n\n                top_ps = top_ps.view(-1)\n                top_is = top_is.view(-1)\n                # p_t, i, d_hidden, lvl, node_parent=None):\n                for index in range(len(top_is)):\n                    p_t = top_ps[index]\n                    i = top_is[index]\n#                     print(p_t, i)\n                    nodes.append(Node(p_t, i, decoder_hidden, di))\n    #             print(nodes)\n    #             print()\n            else:\n            #only fetch top 10\n            \n                #only fetch the nodes w lvl\n                \n                #assumption: nodes still exist whne not in array\n                prev_nodes = [x for x in nodes if x.lvl == di-1]\n                prev_nodes = sorted(prev_nodes, key=lambda x: x.p_sentence.item(), reverse=True)\n                prev_nodes = prev_nodes[:BEAM_WIDTH]\n#                 print(di, len(prev_nodes))\n                nodes = []\n                for node in prev_nodes:\n#                     print(node.p_sentence)\n#                     p_sentence = node.p_sentence.item()\n                    decoder_output, decoder_hidden = decoder(*node.prepareToDecode())\n                    top_ps, top_is = decoder_output.data.topk(BEAM_WIDTH)\n                    top_ps = top_ps.view(-1)\n                    top_is = top_is.view(-1)    \n                    \n                    for index in range(len(top_is)):\n                        p_t = top_ps[index]\n                        i = top_is[index]\n                        child_node = Node(p_t, i, decoder_hidden, di, node)\n                        \n                        if i.item() == EOS_token:\n#                             print(\"found one EOS_token\")\n                            finished_nodes.append(child_node)\n                        else:\n                            nodes.append(child_node)\n#                         print(\"node creations done\")\n                    \n                    \n#                     print(\"node done\")\n#                     print(p_sentence)\n                \n#                 print(\"LVL DONE\")\n\n\n#         print(\"all possible contestants\")\n#         for node in finished_nodes:\n#             print(node.getSentence())\n    \n#         print(\"final output\")\n        final_node = sorted(finished_nodes, key=lambda x: x.p_sentence.item(), reverse=True)[0]\n        return final_node.getTokens()\n#                 decoder_output, decoder_hidden = decoder(*nodes[0].prepareToDecode())\n#         #             print(d_o, d_h)\n#                 top_ps, top_is = decoder_output.data.topk(10)\n# #                 print(top_ps, top_is)\n\n\n#                 top_ps = top_ps.view(-1)\n#                 top_is = top_is.view(-1)\n#                 for index in range(len(top_is)):\n#                     p_t = top_ps[index]\n#                     i = top_is[index]\n# #                     print(p_t, i)\n#                     nodes.append(Node(p_t, i, decoder_hidden, di))\n\n\n\n\n    #             if topi.item() == EOS_token:\n#                 decoded_words.append('<EOS>')\n#                 break\n#             else:\n#                 decoded_words.append(output_lang.index2word[topi.item()])\n            \n            \n            \n            \n#             decoder_input = topi.squeeze().detach()\n            #                              ^avoid copy\n\n#         return decoded_words\nevaluate(encoder_c, encoder_a, decoder, \"the food\", \"great\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#input_c_tensor, input_a_tensor, target_tensor, encoder_c, encoder_a, decoder, encoder_c_optimizer, encoder_a_optimizer, decoder_optimizer\ndef evaluateWithoutBeamSearch(encoder_c, encoder_a, decoder, c, a, max_length=MAX_LENGTH):\n    with torch.no_grad():    \n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoderStep(encoder_c, encoder_a, c, a)\n        decoded_words = []\n        \n        \n        \n        \n        #TODO: BEAM SEARCH\n        for di in range(max_length):\n            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n            \n            topv, topi = F.softmax(decoder_output).data.topk(1)\n#             print(topv, topi)\n#             print(decoder_output.data)\n#             print(topv, topi.item(), output_lang.index2word[topi.item()])\n            \n            \n            \n            \n            if topi.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            else:\n                decoded_words.append(output_lang.index2word[topi.item()])\n            \n            \n            \n            \n            decoder_input = topi.squeeze().detach()\n            #                              ^avoid copy\n\n        return decoded_words\n' '.join(evaluateWithoutBeamSearch(encoder_c, encoder_a, decoder, \"the food is\", \"great\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluateRandomly(encoder_c, encoder_a, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words = evaluate(encoder_c, encoder_a, decoder, pair[0], pair[1])\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluateRandomly(encoder_c, encoder_a, decoder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def DeleteAndRetrieve(sentence, style):\n    c_src = separate(sentence, 0)['c']\n    a_tgt = ' '.join(retrieve(sentence, not style)['a'])\n    return ' '.join(evaluate(encoder_c, encoder_a, decoder, c_src, a_tgt))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence = \"we sit down and we got some really slow and lazy service .\"\nstyle_src = 0\nDeleteAndRetrieve(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"==============================================="},{"metadata":{},"cell_type":"markdown","source":"# DeleteOnly"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resources: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n# Had to modify & adapt most of the code in the tutorial since this isn't translation & data preprocessing is different\n\nSOS_token = 0\nEOS_token = 1\n\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Notes: DELETEONLY first embeds the content\n#c(x, vsrc) into a vector using an RNN. It then\n#concatenates the final hidden state with a learned\n#embedding for vtgt, and feeds this into an RNN\n#decoder to generate y. The decoder attempts to\n#produce words indicative of the source content\n#and target attribute, while remaining fluent.\n\n#Problem 1 -> Embed c into vector. -> Simple GRU autoencoder\n\n# c -> encoder -> code > concatenated -> decoder -> y (sentence)\n# v -> embedding -> code    ^","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepareData():\n    input_lang = Lang(\"input\")\n    output_lang = Lang(\"output\")\n    pairs = []\n    for sentence in d_pos:\n         pairs.append([get_c(sentence, 1), sentence, 1])\n\n    for sentence in d_neg:\n         pairs.append([get_c(sentence, 0), sentence, 0])\n            \n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n        \n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_lang, output_lang, pairs = prepareData()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for pair in d_pos_ref:\n    input_lang.addSentence(pair[0])\n    output_lang.addSentence(pair[1])\nfor pair in d_neg_ref:\n    input_lang.addSentence(pair[0])\n    output_lang.addSentence(pair[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, word_vec_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        \n        self.embedding = nn.Embedding(input_size, word_vec_size)\n        self.gru = nn.GRU(word_vec_size, hidden_size)\n\n    def forward(self, input, hidden):\n        embedded = self.embedding(input).view(1, 1, -1)\n        output = embedded\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class StyleEmbedder(nn.Module):\n    def __init__(self, num_styles, dimensions):\n        super(StyleEmbedder, self).__init__()\n        self.dimensions = dimensions        \n        self.embedding = nn.Embedding(num_styles, dimensions)\n\n    def forward(self, input):\n        embedded = self.embedding(input).view(1, 1, -1)\n        return embedded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Maxout(nn.Module):\n    def __init__(self, pool_size):\n        super().__init__()\n        self._pool_size = pool_size\n\n    def forward(self, x):\n        assert x.shape[1] % self._pool_size == 0, \\\n            'Wrong input last dim size ({}) for Maxout({})'.format(x.shape[1], self._pool_size)\n        m, i = x.view(*x.shape[:1], x.shape[1] // self._pool_size, self._pool_size, *x.shape[2:]).max(2)\n        return m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, word_vec_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(output_size, word_vec_size)\n        self.gru = nn.GRU(word_vec_size, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n        self.maxout = Maxout(1)\n\n    def forward(self, input, hidden):\n        output = self.embedding(input).view(1, 1, -1)\n        output = self.maxout(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Preparing Training Data\ndef indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\ndef tensorFromStyle(style):\n#     one_hot_encoded_style = []\n#     if style:\n#         one_hot_encoded_style = [1,0]\n#     else:\n#         one_hot_encoded_style = [0,1]\n    return torch.tensor(style, dtype=torch.long, device=device).view(-1, 1)\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    style_tensor = tensorFromStyle(pair[2])\n    return (input_tensor, style_tensor, target_tensor)  #add style_tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training\nMAX_LENGTH = 50\n\nteacher_forcing_ratio = 0.5\n\n\ndef train(input_tensor, style_tensor, target_tensor, encoder, style_embedder, decoder, encoder_optimizer, style_embedder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n    encoder_hidden = encoder.initHidden()\n\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n    #style embedding\n    style_embedder_optimizer.zero_grad()\n    \n    \n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n\n    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n    loss = 0\n\n    \n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(\n            input_tensor[ei], encoder_hidden)\n        encoder_outputs[ei] = encoder_output[0, 0]\n\n        \n    decoder_input = torch.tensor([[SOS_token]], device=device)\n    \n    #calculate style embedding\n    style_embedding = style_embedder(style_tensor)\n    \n#     print(\"Encoder Hidden Size: \", encoder_hidden.size())\n#     print(\"Style Embedding Size: \", style_embedding.size())\n    \n    decoder_hidden = torch.cat((encoder_hidden, style_embedding), 2) #TODO: concatenate style embedding\n#     print(\"Concatenated Size: \", decoder_hidden.size())\n    \n    \n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if use_teacher_forcing:\n        # Teacher forcing: Feed the target as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden)\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]  # Teacher forcing\n\n    else:\n        # Without teacher forcing: use its own predictions as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden)\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # detach from history as input\n\n            loss += criterion(decoder_output, target_tensor[di])\n            if decoder_input.item() == EOS_token:\n                break\n\n    loss.backward()\n\n    encoder_optimizer.step()\n    #style embedding\n    style_embedder_optimizer.step()\n    \n    decoder_optimizer.step()\n    \n\n    return loss.item() / target_length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)\n    \nimport time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def trainIters(encoder, style_embedder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n\n    encoder_optimizer = optim.Adadelta(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adadelta(decoder.parameters(), lr=learning_rate)\n    #style\n    style_embedder_optimizer = optim.Adadelta(style_embedder.parameters(), lr=learning_rate)\n    \n    \n    training_pairs = [tensorsFromPair(random.choice(pairs))\n                      for i in range(n_iters)] #TODO: add have style tensor\n    criterion = nn.NLLLoss()\n\n    for iter in range(1, n_iters + 1):\n        training_pair = training_pairs[iter - 1]\n        input_tensor = training_pair[0]\n        style_tensor = training_pair[1]\n        target_tensor = training_pair[2]#TODO: add have style tensor\n        \n        loss = train(input_tensor, style_tensor, target_tensor, encoder, style_embedder,\n                     decoder, encoder_optimizer, style_embedder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if iter % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n                                         iter, iter / n_iters * 100, print_loss_avg))\n\n        if iter % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_vec_size = 128\nhidden_size = 512\nstyle_vec_size = 128\nencoder1 = EncoderRNN(input_lang.n_words, word_vec_size, hidden_size).to(device)\n\ndecoder1 = DecoderRNN(hidden_size + style_vec_size, word_vec_size, output_lang.n_words).to(device)\n                                                #^ + style_vec_size\nstyle_embedder1 = StyleEmbedder(2, style_vec_size).to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainIters(encoder1, style_embedder1, decoder1, 200000, print_every=1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def encoderStep_deleteOnly(encoder, style_embedder, sentence, style, max_length=MAX_LENGTH):\n    input_tensor = tensorFromSentence(input_lang, sentence)\n    style_tensor = tensorFromStyle(style)\n\n    input_length = input_tensor.size()[0]\n    encoder_hidden = encoder.initHidden()\n\n    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(input_tensor[ei],\n                                                 encoder_hidden)\n        encoder_outputs[ei] += encoder_output[0, 0]\n    style_embedding = style_embedder(style_tensor)\n    return torch.cat((encoder_hidden, style_embedding), 2)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ALPHA = 0.7\n\nclass Node:\n    def __init__(self, p_t, i, d_hidden, lvl, node_parent=None):\n        self.p_t = p_t\n        self.i = i\n        self.d_hidden = d_hidden\n        self.lvl = lvl\n        self.node_parent = node_parent\n        \n        self.p_sentence = self.sentenceProb()\n    \n    def prepareToDecode(self):\n        d_in = self.i.squeeze()#.detatch()\n        return d_in, self.d_hidden\n    \n    def sentenceProb(self):\n        if self.node_parent == None:\n            return self.p_t\n        return self.node_parent.sentenceProb() + self.p_t #addition because of log\n    \n    def normProb(self):\n        #Normalised probability\n#         return 1/((self.lvl+1)**ALPHA) * self.sentenceProb()\n        #perplexity\n        return torch.exp(self.sentenceProb()) ** (-1/(self.lvl+1))\n    \n    def getToken(self):\n        return output_lang.index2word[self.i.item()]\n    \n    def getTokens(self):\n        token = [self.getToken()]\n#         print(token)\n        if(self.node_parent == None):\n            return token\n        else:\n             return self.node_parent.getTokens() + token\n#         return tokens\n    def getSentence(self):\n        return ' '.join(self.getTokens())\n# Normalize 1/num words^alpha (alpha = 0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluateWithoutBeamSearch(encoder, style_embedder, decoder, sentence, style, max_length=MAX_LENGTH):  #TODO add style to evaluate\n    with torch.no_grad():\n        \n        \n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoderStep_deleteOnly(encoder, style_embedder, sentence, style)\n        \n        decoded_words = []\n\n        \n        #=================\n        \n        \n        for di in range(max_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden)\n            \n            topv, topi = decoder_output.data.topk(1)\n            \n            \n            if topi.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            else:\n                decoded_words.append(output_lang.index2word[topi.item()])\n\n            decoder_input = topi.squeeze().detach()\n#             print(decoder_input)\n\n        return decoded_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#input_c_tensor, input_a_tensor, target_tensor, encoder_c, encoder_a, decoder, encoder_c_optimizer, encoder_a_optimizer, decoder_optimizer\nBEAM_WIDTH = 10\n\ndef evaluate_deleteOnly(encoder, style_embedder, decoder, sentence, style, max_length=MAX_LENGTH):\n    with torch.no_grad():    \n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoderStep_deleteOnly(encoder, style_embedder, sentence, style)\n        decoded_words = []\n\n        nodes = []\n        finished_nodes = []\n        for di in range(max_length):\n            if di == 0:\n                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n                top_ps, top_is = decoder_output.data.topk(BEAM_WIDTH)\n\n                top_ps = top_ps.view(-1)\n                top_is = top_is.view(-1)\n\n                for index in range(len(top_is)):\n                    p_t = top_ps[index]\n                    i = top_is[index]\n                    nodes.append(Node(p_t, i, decoder_hidden, di))\n\n            else:\n                prev_nodes = [x for x in nodes if x.lvl == di-1]\n                prev_nodes = sorted(prev_nodes, key=lambda x: x.p_sentence.item(), reverse=True)\n                prev_nodes = prev_nodes[:BEAM_WIDTH]\n\n                nodes = []\n                for node in prev_nodes:\n                    decoder_output, decoder_hidden = decoder(*node.prepareToDecode())\n                    top_ps, top_is = decoder_output.data.topk(BEAM_WIDTH)\n                    top_ps = top_ps.view(-1)\n                    top_is = top_is.view(-1)    \n                    \n                    for index in range(len(top_is)):\n                        p_t = top_ps[index]\n                        i = top_is[index]\n                        child_node = Node(p_t, i, decoder_hidden, di, node)\n                        \n                        if i.item() == EOS_token:\n                            finished_nodes.append(child_node)\n                        else:\n                            nodes.append(child_node)\n    \n#         print(\"final output\")\n        final_node = sorted(finished_nodes, key=lambda x: x.p_sentence.item(), reverse=True)[0]\n        return final_node.getSentence()\nevaluate_deleteOnly(encoder1, style_embedder1, decoder1, \"the food\", 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluateRandomly(encoder, style_embedder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        print('style: ', pair[2])\n        \n        \n        output_words = evaluate_deleteOnly(encoder, style_embedder, decoder, pair[0], pair[2])\n        output_sentence = ' '.join(output_words)\n        \n        print('<', output_sentence)\n        print('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluateRandomly(encoder1, style_embedder1, decoder1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def DeleteOnly(sentence, style_src):\n    return evaluate_deleteOnly(encoder1, style_embedder1, decoder1, sentence, not style_src)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence = \"we sit down and we got some really slow and lazy service .\"\nstyle_src = 0\nDeleteOnly(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RetrieveOnly"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_euclidean_distance(c, c2):\n    return torch.dist(get_c_embedding(encoder_c, c), get_c_embedding(encoder_c, c2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RetrieveOnly(sentence, style_src):\n    opposite_dataset = d_neg if style_src else d_pos\n\n    closest_sentence = \"\"\n\n    c_src = get_c(sentence, style_src)\n    # print(c_src)\n\n    min_distance = -1\n    for sentence_b in opposite_dataset:\n        c_tgt = get_c(sentence_b, not style_src)\n\n        dist = get_euclidean_distance(c_src, c_tgt)\n        if min_distance == -1 or dist < min_distance:\n            min_distance = dist\n            closest_sentence = sentence_b\n\n    return closest_sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence = \"we sit down and we got some really slow and lazy service .\"\nstyle_src = 0\nRetrieveOnly(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence = \"we sit down and we got some really slow and lazy service .\"\nstyle_src = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TemplateBased(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RetrieveOnly(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DeleteOnly(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DeleteAndRetrieve(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tried to get this to work for like an hour at a half... But got major school work to do lol, so followed a tutorial instead of doing it from scratch -> only this classifier\n# https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_SPLIT_PERCENT = 0.8\nfrom fastai.text import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(np.random.randn(d_all['labels'].count(), 2))\nmsk = np.random.rand(len(df)) < TRAIN_SPLIT_PERCENT\ntrain = d_all[msk]\ntest = d_all[~msk]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (TextList.from_df(train, cols='text')\n                .split_by_rand_pct(0.2)\n                .label_for_lm()  \n                .databunch(bs=48))\ndata.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner = language_model_learner(data, AWD_LSTM, drop_mult=0.3)\nlearner.lr_find()\n\n# we typically find the point where the slope is steepest\nlearner.recorder.plot()\n\n# Fit the model based on selected learning rate\nlearner.fit_one_cycle(5, 1e-2, moms=(0.8,0.7))\n\n# Tune a little more\nlearner.unfreeze()\nlearner.fit_one_cycle(5, 1e-3, moms=(0.8,0.7))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner.save_encoder('fine_tuned_enc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datalist = TextList.from_df(test, cols='text', vocab=data.vocab)\n\ndata_clas = (TextList.from_df(train, cols='text', vocab=data.vocab)\n             .split_by_rand_pct(0.2)\n             .label_from_df(cols= 'labels')\n             .add_test(test_datalist)\n             .databunch(bs=32))\n\ndata_clas.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_classifier = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n\n# load the encoder saved  \nlearn_classifier.load_encoder('fine_tuned_enc')\n\nlearn_classifier.freeze()\n\n# select the appropriate learning rate\nlearn_classifier.lr_find()\n\n# we typically find the point where the slope is steepest\nlearn_classifier.recorder.plot()\n\n# Fit the model based on selected learning rate\nlearn_classifier.fit_one_cycle(5, 2e-2, moms=(0.8,0.7))\n\n# Tune a little more\nlearn_classifier.freeze_to(-2)\nlearn_classifier.fit_one_cycle(5, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))\n\n# Tune a little more\nlearn_classifier.freeze_to(-3)\nlearn_classifier.fit_one_cycle(5, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))\n\nlearn_classifier.show_results()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence = \"we sit down and we got some really slow and lazy service .\"\nstyle_src = 0\n\ndef predict_style(sentence):\n    predicted_value = learn_classifier.predict(sentence)[0].data[0]\n    if(predicted_value > 0.5):\n        return 1\n    else:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_style(\"bad\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get Scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_scores(func, num_tests=None):\n    if(num_tests == None):\n        pos_refs = d_pos_ref\n        neg_refs = d_neg_ref\n    else:\n        pos_refs = d_pos_ref[:num_tests//2]\n        neg_refs = d_neg_ref[:num_tests//2]\n    \n    num_correct = 0\n    total = 0\n    \n    hypotheses = []\n    references = []\n    \n    for pair in pos_refs:\n        #positive dataset\n        sentence = pair[0]\n        hypothesis = func(sentence, 1)\n        reference = pair[1]\n        \n        hypotheses.append(hypothesis)\n        references.append(reference)\n        \n        predicted_style = predict_style(hypothesis)\n        actual_style = 0\n        if predicted_style == actual_style:\n            num_correct +=1\n        total +=1\n        print(\"H, R, P: \", hypothesis, reference, predicted_style)\n        \n    for pair in neg_refs:\n        #positive dataset\n        sentence = pair[0]\n        hypothesis = func(sentence, 0)\n        reference = pair[1]\n        \n        hypotheses.append(hypothesis)\n        references.append(reference)\n        \n        \n        predicted_style = predict_style(hypothesis)\n        actual_style = 1\n        if predicted_style == actual_style:\n            num_correct +=1\n        total +=1\n        print(\"H, R, P: \", hypothesis, reference, predicted_style)\n    \n    if (num_correct > 0):\n        accuracy = num_correct / total\n    else:\n        accuracy = 0\n        \n    bleu_score = get_moses_multi_bleu(hypotheses, references, True)\n    print(\"Accuracy: \", accuracy)\n    print(\"BLEU: \", bleu_score)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_scores(TemplateBased)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_scores(RetrieveOnly)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_scores(DeleteOnly)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_scores(DeleteAndRetrieve)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}