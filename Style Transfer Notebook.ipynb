{"cells":[{"metadata":{"_uuid":"c6b1fed8-ed7e-43fa-b71c-247b812cddbc","_cell_guid":"9042e3cf-eca5-4811-9883-b76a0774d442","trusted":true},"cell_type":"code","source":"!pip install fse","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ccf0dde-5b9a-46e3-b35f-055f54bd5b54","_cell_guid":"ec08ea8d-2348-4dcf-b86c-9a8329b8abd2","trusted":true},"cell_type":"code","source":"!pip install pytorch-nlp","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f429b54f-3b13-4f52-8cd7-95765498044e","_cell_guid":"54f7e59e-ef49-446c-9058-031d9a2a546e","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport re\nimport string \nimport collections\nimport fse\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchnlp.metrics import get_moses_multi_bleu\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(1)\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c44aa79-ed9f-4fb5-9d67-7eca0832d1d9","_cell_guid":"1bd719a4-6f4f-4ced-a6b1-2218aff64aec","trusted":true},"cell_type":"markdown","source":"# Data Pre-Processing"},{"metadata":{"_uuid":"d3f7b866-b603-47ec-af6a-56e5f5b9da22","_cell_guid":"b3bdb6e7-368b-4625-a3d2-d7b35c8be8a5","trusted":true},"cell_type":"code","source":"#yelp\nroot = \"../input/style-transfer-dataset/yelp/\"\n\nd_pos_path = root+\"sentiment.train.1\"\nd_neg_path = root+\"sentiment.train.0\"\n\n#Problem: Data imbalance? -> decoder might be biased towards positive\nd_pos = pd.read_csv(d_pos_path, sep=\"\\n\", header=None)#.iloc[:,0]\nd_neg = pd.read_csv(d_neg_path, sep=\"\\n\", header=None)#.iloc[:,0]\nd_both = pd.concat((d_pos, d_neg), ignore_index=True)\n\n#Problem: Data imbalance? -> decoder might be biased towards positive\nd_pos = pd.read_csv(d_pos_path, sep=\"\\n\", header=None)#.iloc[:,0]\nd_neg = pd.read_csv(d_neg_path, sep=\"\\n\", header=None)#.iloc[:,0]\nd_both = pd.concat((d_pos, d_neg), ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0047d546-2b93-4410-9452-93efd80c0ff4","_cell_guid":"57eb1f20-46dc-475d-be3f-7adcdd9ce535","trusted":true},"cell_type":"code","source":"d_labels = pd.DataFrame(np.concatenate( ( np.ones((d_pos.size, 1)), np.zeros((d_neg.size, 1)) ) ))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c10ed30-53d4-496f-b506-55365da17cab","_cell_guid":"727f8f3f-5e45-4835-9ab0-711ec671cd96","trusted":true},"cell_type":"code","source":"d_all = pd.concat((d_pos, d_neg), ignore_index=True)\nd_all['labels'] = d_labels\nd_all.columns = ['text', 'labels']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09034409-e789-4180-956f-b214df049e83","_cell_guid":"01a3f41d-d353-4efb-bd9e-6008e232dfdb","trusted":true},"cell_type":"code","source":"cols = d_all.columns.tolist()\ncols = cols[-1:] + cols[:-1]\nd_all = d_all[cols]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"883bb8f1-0c9c-4418-a12c-74279a014ab1","_cell_guid":"a932d178-7cd9-4471-8982-22a5a347e0fa","trusted":true},"cell_type":"code","source":"d_pos=d_pos.iloc[:,0]\nd_neg=d_neg.iloc[:,0]\nd_both=d_both.iloc[:,0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b826c5cc-8c3d-4996-a69d-e85fb5161732","_cell_guid":"c732d02f-79cb-4064-80c6-00bec224e47e","trusted":true},"cell_type":"code","source":"d_pos_ref_path = root+\"reference.1\"\nd_pos_ref = []\nd_pos_ref_file = open(d_pos_ref_path, 'r')\nfor line in d_pos_ref_file.readlines():\n    pair = line.split(\"\\t\")\n    pair[1] = ' '.join(re.findall(r\"\\w+|[^\\w\\s]\", pair[1], re.UNICODE))  #split punctuation\n    d_pos_ref.append(pair)\n    \nd_neg_ref_path = root+\"reference.0\"\nd_neg_ref = []\nd_neg_ref_file = open(d_neg_ref_path, 'r')\nfor line in d_neg_ref_file.readlines():\n    pair = line.split(\"\\t\")\n    pair[1] = ' '.join(re.findall(r\"\\w+|[^\\w\\s]\", pair[1], re.UNICODE))  #split punctuation\n    d_neg_ref.append(pair)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12552eec-3195-4a86-bc23-0320f3d209ea","_cell_guid":"74bb010b-29a1-4439-8874-16fe77fad1ab","trusted":true},"cell_type":"markdown","source":"# Components\n\n### Content & Attributes Separation"},{"metadata":{"_uuid":"d9da177a-da07-4ac3-a45e-c30cc07d66a9","_cell_guid":"ac2981ca-d138-4281-a5aa-2bd5dc8d4117","trusted":true},"cell_type":"code","source":"#Parameters:\nparam_smooth = 1\nparam_threshold = 15\nparam_span = 4\n\nparam_backoff_limit = 3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20863d05-249f-4ccb-850c-7ac334448c18","_cell_guid":"a19438c0-e3dd-4a61-9cbe-6805e6bb6b95","trusted":true},"cell_type":"code","source":"#ngram has punctuation\ndef has_punctuation(ngram): #damn I'm very proud of making this from scratch lol, looks elegant in one line\n    return True in [x in string.punctuation for x in ngram]\n\ndef generate_ngrams(lines, min_length=1, max_length=param_span):\n#     lines = placeholder + lines\n    lengths = range(min_length, max_length + 1)\n    ngrams = {length: [] for length in lengths}\n    queue = collections.deque(maxlen=max_length)\n    \n    def add_queue():\n        current = tuple(queue)\n        for length in lengths:\n            if len(current) >= length and not has_punctuation(current[:length]):\n                ngrams[length].append(current[:length])\n    \n    short_by = 0\n    for line in lines:\n        short_by = max(0, max_length - len(lines))\n        for word in line.split():\n            queue.append(word)\n            if len(queue) >= max_length-short_by:\n                add_queue()                \n\n    while len(queue) > min_length:\n        queue.popleft()\n        add_queue()\n    return ngrams\n\n#modified from & fixed their error of ngram with # of words < 4: https://gist.github.com/benhoyt/dfafeab26d7c02a52ed17b6229f0cb52\ndef count_ngrams(lines, min_length=1, max_length=param_span):\n    \"\"\"Iterate through given lines iterator (file object or list of\n    lines) and return n-gram frequencies. The return value is a dict\n    mapping the length of the n-gram to a collections.Counter\n    object of n-gram tuple and number of times that n-gram occurred.\n    Returned dict includes n-grams of length min_length to max_length.\n    \"\"\"\n    lengths = range(min_length, max_length + 1)\n    ngrams = {length: collections.Counter() for length in lengths}\n    queue = collections.deque(maxlen=max_length)\n\n    # Helper function to add n-grams at start of current queue to dict\n    def add_queue():\n        current = tuple(queue)\n        for length in lengths:\n            if len(current) >= length and not has_punctuation(current[:length]):\n                ngrams[length][current[:length]] += 1\n\n    # Loop through all lines and words and add n-grams to dict\n    short_by = 0\n    for line in lines:\n        short_by = max(0, max_length - len(lines))\n        for word in line.split():\n            queue.append(word)\n            if len(queue) >= max_length - short_by:\n                add_queue()\n\n    # Make sure we get the n-grams at the tail end of the queue\n    while len(queue) > min_length:\n        queue.popleft()\n        add_queue()\n\n    return ngrams","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"964a7cab-8587-4487-a88f-3fb5510cb894","_cell_guid":"faff6114-2244-417c-ba81-61d84ab3e147","trusted":true},"cell_type":"code","source":"#Generate ngram counts for d_pos & d_neg\nd_pos_ngrams_counts = count_ngrams(d_pos.tolist())\nd_neg_ngrams_counts = count_ngrams(d_neg.tolist())\n\ndef get_counts(list1, counted_ngrams):\n    counts = []\n    list1_ngrams = generate_ngrams(list1)\n    list2_counts = counted_ngrams\n    \n    for length in range(param_span,0, -1):\n        for v in list1_ngrams[length]:\n            counts.append([list2_counts[length][v], v])\n    return np.array(counts)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a793bac-9151-4c9c-8c3e-4b0ae1c41f24","_cell_guid":"216c9565-6547-4fd1-a2e5-9718ad209243","trusted":true},"cell_type":"code","source":"#these are methods that will become useful when extracting attribute markers\n#why do we need all this? well... that's like 5 hours of debugging...\ndef flatten(foo):\n    return list(_flatten(foo))\n\ndef _flatten(foo):\n    for x in foo:\n        if isinstance(x, collections.Iterable) and not isinstance(x, str):\n            for y in _flatten(x):\n                yield y\n        else:\n            yield x\n\ndef array_to_string(a):\n    return ' '.join(flatten(a))\n\ndef is_in_string_array(elements, original): #deprecated, does not take into account sequence order\n    return np.isin(array_to_string(elements).split(), array_to_string(original).split()).any()\n\ndef insert_string(string, inserted_string, index):\n    return string[:index] + inserted_string + string[index:]\n\n# modified from https://stackoverflow.com/questions/41752946/replacing-a-character-from-a-certain-index\ndef replace_string(s, newstring, index, nofail=False):\n    # raise an error if index is outside of the string\n    if not nofail and index not in range(len(s)):\n        raise ValueError(\"index outside given string. index:\" + index)\n\n    # if not erroring, but the index is still not in the correct range..\n    if index < 0:  # add it to the beginning\n        return newstring + s\n    if index > len(s):  # add it to the end\n        return s + newstring\n\n    # insert the new string between \"slices\" of the original\n    return s[:index] + newstring + s[index + len(newstring):]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4874fe8-9ea7-45e2-ac27-c999185ef50c","_cell_guid":"f89cd319-04db-4ea3-8d19-e426a29f9515","trusted":true},"cell_type":"code","source":"def get_attribute_markers(s, style_src):\n    sentence = [s]\n    \n    ngrams = get_counts(sentence, d_pos_ngrams_counts)\n    if len(ngrams) > 0:\n        ngrams = ngrams[:,1]\n    \n    pos_counts = get_counts(sentence, d_pos_ngrams_counts)\n    if len(pos_counts) > 0:\n        pos_counts = pos_counts[:,0]\n    \n    neg_counts = get_counts(sentence, d_neg_ngrams_counts)\n    if len(neg_counts) > 0:\n        neg_counts = neg_counts[:,0]\n    \n    \n    if(style_src):\n        importances = (pos_counts + param_smooth) / (neg_counts + param_smooth)\n    else:\n        importances = (neg_counts + param_smooth) / (pos_counts + param_smooth)\n        \n    a = []\n    \n    importances = np.vstack((importances, ngrams)).T\n    for importance in importances:\n        if importance[0] > param_threshold and not is_in_string_array(importance[1], a):\n            a.append(' '.join(importance[1]))\n    return a","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ecfd2f8-490e-4d5c-ace8-7d2b63874dac","_cell_guid":"ee36a16a-781d-4ffe-ba97-046a23fbb42f","trusted":true},"cell_type":"code","source":"def separate(sentence, style_src):\n    attributes = get_attribute_markers(sentence, style_src)\n    c = sentence\n\n    replace_indexes = []\n    for a in attributes:\n        replace_index = -1\n        replace_index = c.find(a)\n        replace_indexes.append(replace_index)\n        c = c.replace(a, \" \"*len(a))\n        \n    if len(attributes) == 0:\n        return {'c': c, 'a': [], 'i': [], 's': sentence}\n    \n    replace_indexes, attributes = zip(*sorted(zip(replace_indexes, attributes)))\n    return {'c': c, 'a': attributes, 'i': replace_indexes, 's': sentence}\n\ndef get_c(sentence, style):\n    return re.sub(' +', ' ', separate(sentence, style)['c'])\n\ndef get_a(sentence, style):\n    a = separate(sentence, style)['a']\n    if len(a) > 0:\n        return ' '.join(a)\n    else:\n        return \"\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da94741e-80e0-4e0e-93df-6bd745a5d05e","_cell_guid":"0877a593-aaef-46f8-bfe8-949fe4880702","trusted":true},"cell_type":"markdown","source":"### TF-IDF Distance"},{"metadata":{"_uuid":"2d95454b-5cad-4a7d-b691-84624680c9a6","_cell_guid":"29e6bf0a-8e98-40a0-acaf-aae4a21046cb","trusted":true},"cell_type":"code","source":"# ===== TF-IDF Weighted Word Overlap ===== #\n# docs pre-processing\ndocs = d_both.tolist()\n\n# creating dict_idf = {word: idf}\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vectorizer=TfidfVectorizer(use_idf=True, stop_words=None)\ntfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(docs)\ndict_idf = dict(zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer.idf_))\n\ndef get_overlap(a, b):\n#     print(a, b)\n    a_counter = collections.Counter(a.split())\n    b_counter = collections.Counter(b.split())\n    overlap = a_counter & b_counter\n    return overlap\n\ndef get_weighted_overlap(a, b):\n    overlap = get_overlap(a, b)\n    a_counter = collections.Counter(a.split())\n    #calculate\n    weighted_overlap = 0\n    for word in overlap:\n\n        word_tf = a_counter[word]#/len(a.split()) -> commented out cause division by constant value doesn't matter\n\n        get_idf = dict_idf.get(word)\n        word_idf = 1 if get_idf == None else get_idf #get rid of error when idf not in dict \n\n        word_tfidf = word_tf*word_idf\n        weighted_overlap+=overlap[word]*word_tfidf\n\n    return weighted_overlap\n\ndef get_closest_sentence_tfidf(sentence, style_src):\n    opposite_dataset = d_neg if style_src else d_pos\n\n    highest_overlap = 0\n    closest_sentence = \"\"\n    \n    min_attribute_markers=len(get_attribute_markers(sentence, style_src))\n    num_markers = 0\n    \n    previous_sentences = []\n    backoff_count = 0\n    while(num_markers < min_attribute_markers and backoff_count < param_backoff_limit):\n        for sentence_b in opposite_dataset:\n            weighted_overlap = get_weighted_overlap(sentence, sentence_b)\n            if weighted_overlap > highest_overlap and sentence_b not in previous_sentences:\n                highest_overlap = weighted_overlap\n                closest_sentence = sentence_b\n        highest_overlap = 0 \n        backoff_count += 1\n        previous_sentences.append(closest_sentence)\n        num_markers = len(get_attribute_markers(closest_sentence, not style_src))\n    \n    return closest_sentence","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70eb8b14-7b45-4487-807b-da356dca4d0d","_cell_guid":"70d191fc-e856-497f-8605-8237123a8296","trusted":true},"cell_type":"code","source":"# Retrieve using tfidf\ndef retrieve(sentence, style_src):\n    return separate(get_closest_sentence_tfidf(sentence, style_src), not style_src)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1217dd53-21b5-4afd-b658-b256e70bde82","_cell_guid":"26d9fdb4-8875-4bcf-871a-149179c3b375","trusted":true},"cell_type":"markdown","source":"### Template Based"},{"metadata":{"_uuid":"f1379660-d1b3-41f5-bcc8-ea896175f9bf","_cell_guid":"3b5df3c6-a6fc-4cb5-ab29-e5540a4ea905","trusted":true},"cell_type":"code","source":"def insert_multi(s, indexes):\n    d = {\n        'w1': {'begin':'0', 'end':'3', 'w':'BIG'},\n        'w2': {'being':'7', 'end':'7', 'w':'BARKED'}\n    }\n    \n    \n    final_s = re.sub('|'.join('\\{}'.format(s[int(b['end'])]) for _, b in d.items()), \"{}\", s).format(*[c['w'] for _, c in sorted(d.items(), key=lambda x:int(x[0][-1]))])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"744c39bc-c77a-451a-b4ba-0476c83f64d4","_cell_guid":"414fddd4-45c9-477d-8f6f-bccc9f6898b1","trusted":true},"cell_type":"code","source":"def TemplateBased(sentence, style_src):\n    \n    separated_src = separate(sentence, style_src)\n    c_src = separated_src['c']\n    replace_indexes = separated_src['i']\n    \n    separated_tgt = retrieve(sentence, style_src)\n    a_tgt = separated_tgt['a']\n\n    missing_attributes =len(replace_indexes) - len(a_tgt)\n    \n    if len(a_tgt) > 0:\n        for i in range(missing_attributes):\n            a_tgt += (a_tgt[0],)\n    \n    output = c_src\n\n    #deprecated insertion, now uses replace\n    #loops backwards as by inserting backwards, you don't need to take into account the increasing length \n#     for i in range(len(replace_indexes)-1, -1, -1):\n#         output = insert_string(output, a_tgt[i]+\" \", replace_indexes[i])\n\n#     #replace\n#     for i in range(len(replace_indexes)):\n#         if replace_indexes[i] >= 0\n#             output = replace_string(output, a_tgt[i], replace_indexes[i])\n\n    #NEW hackery way: insert back to front, then split & join -> to account of tgt attribute length > src attribute\n    for i in range(len(replace_indexes)-1, -1, -1):\n        if i < len(a_tgt):\n            output = insert_string(output, a_tgt[i]+\" \", replace_indexes[i])\n    \n    output = ' '.join(output.split())\n    return output","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e4f35da-2db6-4c1a-ae9c-8bf224fb383a","_cell_guid":"68c89c95-eaec-4d5c-883d-7c2e220690bb","trusted":true},"cell_type":"code","source":"sentence = \"we got down and we got some really slow and lazy service .\"\nstyle_src = 0\nTemplateBased(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"205c2650-da30-4607-ab9c-57750cb89312","_cell_guid":"d3efc605-2966-47b1-a660-35ae609439a2","trusted":true},"cell_type":"markdown","source":"# Model"},{"metadata":{"_uuid":"06665b00-1550-4fd0-998e-0df4e5fa1ff7","_cell_guid":"42b9fc2a-bfcc-42fb-b5d7-28f4c540dbc7","trusted":true},"cell_type":"markdown","source":"### DeleteAndRetrieve"},{"metadata":{"_uuid":"fba6e335-f479-4c39-a81a-bfc76cfaaba5","_cell_guid":"d4c413fa-aed4-44af-8558-81d953c92fe1","trusted":true},"cell_type":"code","source":"# Resources: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n# Had to modify & adapt most of the code in the tutorial since this isn't translation & data preprocessing is different\n\nSOS_token = 0\nEOS_token = 1\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8de5ac9c-92be-41dc-bc18-fb817ca032b1","_cell_guid":"ca02b8bf-2fde-4d3e-8796-e1f91b326cf7","trusted":true},"cell_type":"code","source":"def get_total_overlap(a, b):\n    return len(list(get_overlap(a, b).elements()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8337bddb-0ff8-4b5a-84d7-f7a7393d6dfd","_cell_guid":"b9f2f97b-e03b-4860-82d5-f08ccb911ab5","trusted":true},"cell_type":"code","source":"noise_chance = 0.1\n\ndef prepareData():\n    input_lang = Lang(\"input\")\n    output_lang = Lang(\"output\")\n    \n    d_pos_a = []\n    \n    pairs_pos = []\n    for sentence in d_pos:\n        c = get_c(sentence, 1)\n        a = get_a(sentence, 1)\n        d_pos_a.append(a)\n        pairs_pos.append([c, a, sentence])\n    \n    d_neg_a = []\n    \n    pairs_neg = []\n    for sentence in d_neg:\n        c = get_c(sentence, 0)\n        a = get_a(sentence, 0)\n        d_neg_a.append(a)\n        pairs_neg.append([c, a, sentence])\n    \n    #adding noise for pos\n    for pair in pairs_pos:\n        if random.random() < noise_chance:\n            real_a = pair[1].split()\n\n            if(len(real_a) == 0):\n                continue\n\n            for a in d_pos_a:\n                if(len(a) == 0):\n                    continue\n                a = a.split()\n\n                overlap = get_total_overlap(' '.join(real_a), ' '.join(a))\n                if overlap > 0 and ((overlap == len(real_a) - 1 and len(real_a) - len(a) == 1) or (overlap == len(real_a) and len(real_a) - len(a) == -1)):\n                    real_a = a\n                    break;\n            pair[1] = ' '.join(real_a)\n    \n    \n    #adding noise for neg\n    for pair in pairs_neg:\n        if random.random() < noise_chance:\n            real_a = pair[1].split()\n            if(len(real_a) == 0):\n                continue\n\n            for a in d_neg_a:\n                if(len(a) == 0):\n                    continue\n                a = a.split()\n\n                overlap = get_total_overlap(' '.join(real_a), ' '.join(a))\n                if overlap > 0 and ((overlap == len(real_a) - 1 and len(real_a) - len(a) == 1) or (overlap == len(real_a) and len(real_a) - len(a) == -1)):\n                    real_a = a\n                    break;\n            pair[1] = ' '.join(real_a)\n\n            \n    pairs = np.concatenate((pairs_pos, pairs_neg), 0)\n\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        input_lang.addSentence(pair[1])\n        output_lang.addSentence(pair[2])\n        \n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d68f33b8-0de7-4e1a-b829-da7c1e1b3c2f","_cell_guid":"b1d4e544-a1fd-463a-871e-1f5c8f61364a","trusted":true},"cell_type":"code","source":"input_lang, output_lang, pairs = prepareData()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65d0f969-c99b-454e-85ec-0ddb822ab2d4","_cell_guid":"48a4ac7a-b75c-4893-b3f5-7b588a36f47d","trusted":true},"cell_type":"code","source":"for pair in d_pos_ref:\n    input_lang.addSentence(pair[0])\n    output_lang.addSentence(pair[1])\nfor pair in d_neg_ref:\n    input_lang.addSentence(pair[0])\n    output_lang.addSentence(pair[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1449bee7-9256-4bf5-9843-851f0e369ec7","_cell_guid":"0c0f73cd-5b81-4a6f-982f-d58c97ef898e","trusted":true},"cell_type":"code","source":"class Maxout(nn.Module):\n    def __init__(self, pool_size):\n        super().__init__()\n        self._pool_size = pool_size\n\n    def forward(self, x):\n        assert x.shape[1] % self._pool_size == 0, \\\n            'Wrong input last dim size ({}) for Maxout({})'.format(x.shape[1], self._pool_size)\n        m, i = x.view(*x.shape[:1], x.shape[1] // self._pool_size, self._pool_size, *x.shape[2:]).max(2)\n        return m","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57f20703-95b6-4083-be20-65e5e6a3cb85","_cell_guid":"c0224043-5a58-4156-9fc4-fe7b1c99f503","trusted":true},"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, word_vec_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        \n        self.embedding = nn.Embedding(input_size, word_vec_size)\n        self.gru = nn.GRU(word_vec_size, hidden_size)\n\n    def forward(self, input, hidden):\n        embedded = self.embedding(input).view(1, 1, -1)\n        output = embedded\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"847b3c71-4912-48c7-bd4f-f5b8cdf8b1ae","_cell_guid":"c80ef555-8e25-4bce-9dfb-2035c84a5d19","trusted":true},"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, word_vec_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.embedding = nn.Embedding(output_size, word_vec_size)\n        self.gru = nn.GRU(word_vec_size, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n        self.maxout = Maxout(1)\n\n    def forward(self, input, hidden):\n        output = self.embedding(input).view(1, 1, -1)\n        output = self.maxout(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d007820-383d-44a6-8605-cc4f550946e5","_cell_guid":"101d54f8-3698-4861-af7d-fa6131891ff7","trusted":true},"cell_type":"code","source":"#Preparing Training Data\ndef indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\n\ndef tensorsFromPair(pair):\n    input_c_tensor = tensorFromSentence(input_lang, pair[0])\n    input_a_tensor = tensorFromSentence(input_lang, pair[1])\n    target_tensor = tensorFromSentence(output_lang, pair[2])\n    return (input_c_tensor, input_a_tensor, target_tensor)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96050308-b9b3-4731-ab56-db1f027b68e4","_cell_guid":"00ae9c50-3c5d-4cbd-a68a-7358df9dca9a","trusted":true},"cell_type":"code","source":"#Training\nMAX_LENGTH = 50\n\nteacher_forcing_ratio = 0.5\n\n\ndef train(input_c_tensor, input_a_tensor, target_tensor, encoder_c, encoder_a, decoder, encoder_c_optimizer, encoder_a_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n    encoder_c_hidden = encoder_c.initHidden()\n    encoder_a_hidden = encoder_a.initHidden()\n\n    encoder_a_optimizer.zero_grad()\n    encoder_c_optimizer.zero_grad()\n\n    decoder_optimizer.zero_grad()\n\n    input_c_length = input_c_tensor.size(0)\n    input_a_length = input_a_tensor.size(0)\n    \n    target_length = target_tensor.size(0)\n\n    encoder_c_outputs = torch.zeros(max_length, encoder_c.hidden_size, device=device)\n    encoder_a_outputs = torch.zeros(max_length, encoder_a.hidden_size, device=device)\n    \n    loss = 0\n\n    for ei in range(input_c_length):\n        encoder_c_output, encoder_c_hidden = encoder_c(\n            input_c_tensor[ei], encoder_c_hidden)\n        encoder_c_outputs[ei] = encoder_c_output[0, 0]\n    \n    for ei in range(input_a_length):\n        encoder_a_output, encoder_a_hidden = encoder_a(\n            input_a_tensor[ei], encoder_a_hidden)\n        encoder_a_outputs[ei] = encoder_a_output[0, 0]\n\n    \n    decoder_input = torch.tensor([[SOS_token]], device=device)\n    \n    decoder_hidden = torch.cat((encoder_c_hidden, encoder_a_hidden), 2)\n    \n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if use_teacher_forcing:\n        # Teacher forcing: Feed the target as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden)\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]  # Teacher forcing\n\n    else:\n        # Without teacher forcing: use its own predictions as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden)\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # detach from history as input\n\n            loss += criterion(decoder_output, target_tensor[di])\n            if decoder_input.item() == EOS_token:\n                break\n\n    loss.backward()\n    \n    encoder_c_optimizer.step()\n    encoder_a_optimizer.step()\n    decoder_optimizer.step()\n\n    return loss.item() / target_length","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e4c69db-78cc-4d60-8fb8-bbb274e5e541","_cell_guid":"0657a67d-0941-4041-994a-287d496a7dc3","trusted":true},"cell_type":"code","source":"import time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a55454de-ae36-4ec9-9352-58a909b79ef3","_cell_guid":"5d433351-21f7-4876-a7aa-2f6ef6f9fd91","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82dac91a-fe20-4387-9db3-c10b5de19da2","_cell_guid":"178b8b13-99d4-44c2-9057-eaa5e9dc6c55","trusted":true},"cell_type":"code","source":"def trainIters(encoder_a, encoder_c, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n    \n    encoder_c_optimizer = optim.Adadelta(encoder_c.parameters(), lr=learning_rate)\n    encoder_a_optimizer = optim.Adadelta(encoder_a.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adadelta(decoder.parameters(), lr=learning_rate)\n    training_pairs = [tensorsFromPair(random.choice(pairs))\n                      for i in range(n_iters)]\n    criterion = nn.NLLLoss()\n\n    for iter in range(1, n_iters + 1):\n        training_pair = training_pairs[iter - 1]\n        input_a_tensor = training_pair[0]\n        input_c_tensor = training_pair[1]\n        \n        target_tensor = training_pair[2]\n        loss = train(input_c_tensor, input_a_tensor, target_tensor, encoder_c, encoder_a,\n                     decoder, encoder_c_optimizer, encoder_c_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if iter % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n                                         iter, iter / n_iters * 100, print_loss_avg))\n\n        if iter % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"197c6c1b-16e8-478c-8000-b7af3be2443c","_cell_guid":"31176cf6-5992-4978-ad82-19a0b1ee50a1","trusted":true},"cell_type":"code","source":"word_vec_size = 128\nhidden_size = 512\nencoder_c = EncoderRNN(input_lang.n_words, word_vec_size, hidden_size).to(device)\nencoder_a = EncoderRNN(input_lang.n_words, word_vec_size, hidden_size).to(device)\n\ndecoder = DecoderRNN(hidden_size + hidden_size, word_vec_size, output_lang.n_words).to(device)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3cc8d4a0-ed10-482e-acfb-e6846114b958","_cell_guid":"b9d68946-3562-4214-b48c-245bf2f983db","trusted":true},"cell_type":"code","source":"trainIters(encoder_c, encoder_a, decoder, 200000, print_every=1000)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b72958b-e8fd-4a67-9e0c-be247b433ed4","_cell_guid":"8bfa4d03-d54e-4294-858a-bb221be408c6","trusted":true},"cell_type":"code","source":"def encoderStep(encoder_c, encoder_a, c, a, max_length=MAX_LENGTH):\n    input_c_tensor = tensorFromSentence(input_lang, c)\n    input_a_tensor = tensorFromSentence(input_lang, a)\n\n    input_c_length = input_c_tensor.size()[0]\n    input_a_length = input_a_tensor.size()[0]\n\n    encoder_c_hidden = encoder_c.initHidden()\n    encoder_a_hidden = encoder_a.initHidden()\n\n    encoder_c_outputs = torch.zeros(max_length, encoder_c.hidden_size, device=device)\n    encoder_a_outputs = torch.zeros(max_length, encoder_a.hidden_size, device=device)\n    \n    for ei in range(input_c_length):\n        encoder_c_output, encoder_c_hidden = encoder_c(input_c_tensor[ei],\n                                                 encoder_c_hidden)\n        encoder_c_outputs[ei] += encoder_c_output[0, 0]\n\n\n    for ei in range(input_a_length):\n        encoder_a_output, encoder_a_hidden = encoder_a(input_a_tensor[ei],\n                                                 encoder_a_hidden)\n        encoder_a_outputs[ei] += encoder_a_output[0, 0]\n    \n\n    \n    return torch.cat((encoder_c_hidden, encoder_a_hidden), 2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e8721f3-8b20-4463-98a6-017aa915d429","_cell_guid":"307f0abf-7685-4ae9-8fe5-cbeb41fce2c0","trusted":true},"cell_type":"code","source":"def get_c_embedding(encoder_c, c, max_length=MAX_LENGTH):\n    input_c_tensor = tensorFromSentence(input_lang, c)\n    \n    input_c_length = input_c_tensor.size()[0]\n\n    encoder_c_hidden = encoder_c.initHidden()\n\n    encoder_c_outputs = torch.zeros(max_length, encoder_c.hidden_size, device=device)\n    \n    for ei in range(input_c_length):\n        encoder_c_output, encoder_c_hidden = encoder_c(input_c_tensor[ei],\n                                                 encoder_c_hidden)\n        encoder_c_outputs[ei] += encoder_c_output[0, 0]\n        \n    return encoder_c_hidden","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a69317fa-6667-4da0-8eec-b5a1b2bb2e85","_cell_guid":"fd5bd621-1802-40bb-99a4-6a125c2edf9f","trusted":true},"cell_type":"code","source":"ALPHA = 0.7\n\nclass Node:\n    def __init__(self, p_t, i, d_hidden, lvl, node_parent=None):\n        self.p_t = p_t\n        self.i = i\n        self.d_hidden = d_hidden\n        self.lvl = lvl\n        self.node_parent = node_parent\n        \n        self.p_sentence = self.sentenceProb()\n    \n    def prepareToDecode(self):\n        d_in = self.i.squeeze()#.detatch()\n        return d_in, self.d_hidden\n    \n    def sentenceProb(self):\n        if self.node_parent == None:\n            return self.p_t\n        return self.node_parent.sentenceProb() + self.p_t #addition because of log\n    \n    def normProb(self):\n        #Normalised probability\n#         return 1/((self.lvl+1)**ALPHA) * self.sentenceProb()\n        #perplexity\n        return torch.exp(self.sentenceProb()) ** (-1/(self.lvl+1))\n    \n    def getToken(self):\n        return output_lang.index2word[self.i.item()]\n    \n    def getTokens(self):\n        token = [self.getToken()]\n\n        if(self.node_parent == None):\n            return token\n        else:\n             return self.node_parent.getTokens() + token\n            \n    def getSentence(self):\n        return ' '.join(self.getTokens())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ac35286-f6a8-42f7-b37c-57c7ba618648","_cell_guid":"d37fcc9d-2b10-47ee-8ea6-004c1cb9f783","trusted":true},"cell_type":"code","source":"BEAM_WIDTH = 10\n\ndef evaluate(encoder_c, encoder_a, decoder, c, a, max_length=MAX_LENGTH):\n    with torch.no_grad():    \n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoderStep(encoder_c, encoder_a, c, a)\n        decoded_words = []\n        \n        #BEAM SEARCH\n        \n        nodes = []\n        finished_nodes = []\n        for di in range(max_length):\n            if di == 0:\n                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n                top_ps, top_is = decoder_output.data.topk(BEAM_WIDTH)\n                top_ps = top_ps.view(-1)\n                top_is = top_is.view(-1)\n                for index in range(len(top_is)):\n                    p_t = top_ps[index]\n                    i = top_is[index]\n                    nodes.append(Node(p_t, i, decoder_hidden, di))\n            else:\n                prev_nodes = [x for x in nodes if x.lvl == di-1]\n                prev_nodes = sorted(prev_nodes, key=lambda x: x.p_sentence.item(), reverse=True)\n                prev_nodes = prev_nodes[:BEAM_WIDTH]\n                nodes = []\n                for node in prev_nodes:\n                    decoder_output, decoder_hidden = decoder(*node.prepareToDecode())\n                    top_ps, top_is = decoder_output.data.topk(BEAM_WIDTH)\n                    top_ps = top_ps.view(-1)\n                    top_is = top_is.view(-1)    \n                    \n                    for index in range(len(top_is)):\n                        p_t = top_ps[index]\n                        i = top_is[index]\n                        child_node = Node(p_t, i, decoder_hidden, di, node)\n                        \n                        if i.item() == EOS_token:\n                            finished_nodes.append(child_node)\n                        else:\n                            nodes.append(child_node)\n\n        final_node = sorted(finished_nodes, key=lambda x: x.p_sentence.item(), reverse=True)[0]\n        return final_node.getTokens()\n\nevaluate(encoder_c, encoder_a, decoder, \"the food\", \"great\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f00f957-1220-4167-bb64-d9bf6eb20cbd","_cell_guid":"65f9b956-d96f-4fb8-bd3c-70c086f05a50","trusted":true},"cell_type":"code","source":"def evaluateWithoutBeamSearch(encoder_c, encoder_a, decoder, c, a, max_length=MAX_LENGTH):\n    with torch.no_grad():    \n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoderStep(encoder_c, encoder_a, c, a)\n        decoded_words = []\n        \n        #BEAM SEARCH\n        for di in range(max_length):\n            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n            \n            topv, topi = F.softmax(decoder_output).data.topk(1)\n\n            if topi.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            else:\n                decoded_words.append(output_lang.index2word[topi.item()])\n            \n            decoder_input = topi.squeeze().detach()\n\n        return decoded_words\n' '.join(evaluateWithoutBeamSearch(encoder_c, encoder_a, decoder, \"the food is\", \"great\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b058ec7-d195-463c-a2f9-0e50850d449f","_cell_guid":"fede1d64-1aba-46d1-aede-0c1fe8f692ee","trusted":true},"cell_type":"code","source":"def evaluateRandomly(encoder_c, encoder_a, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words = evaluate(encoder_c, encoder_a, decoder, pair[0], pair[1])\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"744551ce-1754-4d30-890b-221f60689c9c","_cell_guid":"02a3c54d-0080-4a6f-bf6c-8a5b763e58e2","trusted":true},"cell_type":"code","source":"evaluateRandomly(encoder_c, encoder_a, decoder)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc74ae4c-e048-465c-86fd-ccb9e47b34e6","_cell_guid":"4ef2b882-9680-4239-9cab-5c436d3052ad","trusted":true},"cell_type":"code","source":"def DeleteAndRetrieve(sentence, style):\n    c_src = separate(sentence, 0)['c']\n    a_tgt = ' '.join(retrieve(sentence, not style)['a'])\n    return ' '.join(evaluate(encoder_c, encoder_a, decoder, c_src, a_tgt))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ecc5cfc1-7d98-4323-8a39-86006f260dde","_cell_guid":"43ef231b-6dd4-4458-b42d-2feef61d8b67","trusted":true},"cell_type":"code","source":"sentence = \"we sit down and we got some really slow and lazy service .\"\nstyle_src = 0\nDeleteAndRetrieve(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa389452-3b09-4e95-91c5-b6c1173c062e","_cell_guid":"05c54362-6b83-4dbf-b11b-08db632cb7c5","trusted":true},"cell_type":"markdown","source":"==============================================="},{"metadata":{"_uuid":"fbbeb68f-fc0e-45e1-bb5f-9c258d01c258","_cell_guid":"21a9ac2d-bed9-4412-a819-a8dd58ff9bea","trusted":true},"cell_type":"markdown","source":"# DeleteOnly"},{"metadata":{"_uuid":"9a28ed16-8668-473c-8c0b-c55e20747f5e","_cell_guid":"214ccaf1-68a0-4aa8-93d0-ed6eab1b7bff","trusted":true},"cell_type":"code","source":"# Resources: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n# Had to modify & adapt most of the code in the tutorial since this isn't translation & data preprocessing is different\n\nSOS_token = 0\nEOS_token = 1\n\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca19ee8e-33dc-449b-a645-3db20c8aad82","_cell_guid":"c6e5478c-c4fc-464d-9ea2-8ea0deb4d326","trusted":true},"cell_type":"code","source":"#Notes: DELETEONLY first embeds the content\n#c(x, vsrc) into a vector using an RNN. It then\n#concatenates the final hidden state with a learned\n#embedding for vtgt, and feeds this into an RNN\n#decoder to generate y. The decoder attempts to\n#produce words indicative of the source content\n#and target attribute, while remaining fluent.\n\n#Problem 1 -> Embed c into vector. -> Simple GRU autoencoder\n\n# c -> encoder -> code > concatenated -> decoder -> y (sentence)\n# v -> embedding -> code    ^","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d00810f2-8cd2-4986-afac-a07a586dbcc7","_cell_guid":"590d6412-3762-4b67-be97-1f9ddc929647","trusted":true},"cell_type":"code","source":"def prepareData():\n    input_lang = Lang(\"input\")\n    output_lang = Lang(\"output\")\n    pairs = []\n    for sentence in d_pos:\n         pairs.append([get_c(sentence, 1), sentence, 1])\n\n    for sentence in d_neg:\n         pairs.append([get_c(sentence, 0), sentence, 0])\n            \n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n        \n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37d2a811-2285-41b4-9213-f26760ee7d59","_cell_guid":"50232e8f-2501-401a-b268-8206fd6c81e9","trusted":true},"cell_type":"code","source":"input_lang, output_lang, pairs = prepareData()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edcf14bd-6799-41b7-8067-7c4570ebacb5","_cell_guid":"45972d11-9e65-46c1-b84b-36ba37c7ff94","trusted":true},"cell_type":"code","source":"for pair in d_pos_ref:\n    input_lang.addSentence(pair[0])\n    output_lang.addSentence(pair[1])\nfor pair in d_neg_ref:\n    input_lang.addSentence(pair[0])\n    output_lang.addSentence(pair[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"154cdf1d-f87f-45f4-a4db-2a8f7fd4a6d4","_cell_guid":"c9e34413-e8c6-4ec8-a702-cda57b5acc2c","trusted":true},"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, word_vec_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        \n        self.embedding = nn.Embedding(input_size, word_vec_size)\n        self.gru = nn.GRU(word_vec_size, hidden_size)\n\n    def forward(self, input, hidden):\n        embedded = self.embedding(input).view(1, 1, -1)\n        output = embedded\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"268e801c-75c1-4fab-874f-66d52cf0e724","_cell_guid":"48aac433-0f05-4c9b-aa4a-2416f3ba93ca","trusted":true},"cell_type":"code","source":"class StyleEmbedder(nn.Module):\n    def __init__(self, num_styles, dimensions):\n        super(StyleEmbedder, self).__init__()\n        self.dimensions = dimensions        \n        self.embedding = nn.Embedding(num_styles, dimensions)\n\n    def forward(self, input):\n        embedded = self.embedding(input).view(1, 1, -1)\n        return embedded","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41708ee8-d343-458e-b7ef-7c1ad0fed973","_cell_guid":"54b46b00-7132-42fe-8b6e-4412117fa40d","trusted":true},"cell_type":"code","source":"class Maxout(nn.Module):\n    def __init__(self, pool_size):\n        super().__init__()\n        self._pool_size = pool_size\n\n    def forward(self, x):\n        assert x.shape[1] % self._pool_size == 0, \\\n            'Wrong input last dim size ({}) for Maxout({})'.format(x.shape[1], self._pool_size)\n        m, i = x.view(*x.shape[:1], x.shape[1] // self._pool_size, self._pool_size, *x.shape[2:]).max(2)\n        return m","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de2d5e20-7865-4f65-a6e7-c67bb890d78a","_cell_guid":"4303038c-a728-4ccb-bfd9-60089610ac66","trusted":true},"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, word_vec_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(output_size, word_vec_size)\n        self.gru = nn.GRU(word_vec_size, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n        self.maxout = Maxout(1)\n\n    def forward(self, input, hidden):\n        output = self.embedding(input).view(1, 1, -1)\n        output = self.maxout(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"318495dc-eb33-49f4-958d-d26e9cecde62","_cell_guid":"2f732e74-619b-49cf-8148-93819f6568d0","trusted":true},"cell_type":"code","source":"#Preparing Training Data\ndef indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\ndef tensorFromStyle(style):\n#     one_hot_encoded_style = []\n#     if style:\n#         one_hot_encoded_style = [1,0]\n#     else:\n#         one_hot_encoded_style = [0,1]\n    return torch.tensor(style, dtype=torch.long, device=device).view(-1, 1)\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    style_tensor = tensorFromStyle(pair[2])\n    return (input_tensor, style_tensor, target_tensor)  #add style_tensor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc9b2e12-435b-4607-9c5b-ae96828d3e5e","_cell_guid":"b5979fdc-b2ff-43f6-9082-000ecce5126b","trusted":true},"cell_type":"code","source":"#Training\nMAX_LENGTH = 50\n\nteacher_forcing_ratio = 0.5\n\n\ndef train(input_tensor, style_tensor, target_tensor, encoder, style_embedder, decoder, encoder_optimizer, style_embedder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n    encoder_hidden = encoder.initHidden()\n\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n    #style embedding\n    style_embedder_optimizer.zero_grad()\n    \n    \n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n\n    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n    loss = 0\n\n    \n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(\n            input_tensor[ei], encoder_hidden)\n        encoder_outputs[ei] = encoder_output[0, 0]\n\n        \n    decoder_input = torch.tensor([[SOS_token]], device=device)\n    \n    #calculate style embedding\n    style_embedding = style_embedder(style_tensor)\n    \n    decoder_hidden = torch.cat((encoder_hidden, style_embedding), 2) #TODO: concatenate style embedding\n    \n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if use_teacher_forcing:\n        # Teacher forcing: Feed the target as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden)\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]  # Teacher forcing\n\n    else:\n        # Without teacher forcing: use its own predictions as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden)\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # detach from history as input\n\n            loss += criterion(decoder_output, target_tensor[di])\n            if decoder_input.item() == EOS_token:\n                break\n\n    loss.backward()\n\n    encoder_optimizer.step()\n    #style embedding\n    style_embedder_optimizer.step()\n    \n    decoder_optimizer.step()\n    \n\n    return loss.item() / target_length","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c44f1125-0f44-45e2-9c3e-7c385bc3dc9d","_cell_guid":"facfc7fb-52d4-4607-8df3-1ba2e6be9400","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)\n    \nimport time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dbecd1db-fcfb-4d4c-b963-8a15b8fb14fc","_cell_guid":"be87b9cf-e2ae-41cf-8d10-9fcba8f14520","trusted":true},"cell_type":"code","source":"def trainIters(encoder, style_embedder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n\n    encoder_optimizer = optim.Adadelta(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adadelta(decoder.parameters(), lr=learning_rate)\n    #style\n    style_embedder_optimizer = optim.Adadelta(style_embedder.parameters(), lr=learning_rate)\n    \n    \n    training_pairs = [tensorsFromPair(random.choice(pairs))\n                      for i in range(n_iters)]\n    criterion = nn.NLLLoss()\n\n    for iter in range(1, n_iters + 1):\n        training_pair = training_pairs[iter - 1]\n        input_tensor = training_pair[0]\n        style_tensor = training_pair[1]\n        target_tensor = training_pair[2]\n        \n        loss = train(input_tensor, style_tensor, target_tensor, encoder, style_embedder,\n                     decoder, encoder_optimizer, style_embedder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if iter % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n                                         iter, iter / n_iters * 100, print_loss_avg))\n\n        if iter % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb531fff-0208-422f-9bca-a91f0d7696b9","_cell_guid":"89ec3c82-4d13-4214-8ca7-1e5b70688b2e","trusted":true},"cell_type":"code","source":"word_vec_size = 128\nhidden_size = 512\nstyle_vec_size = 128\nencoder1 = EncoderRNN(input_lang.n_words, word_vec_size, hidden_size).to(device)\n\ndecoder1 = DecoderRNN(hidden_size + style_vec_size, word_vec_size, output_lang.n_words).to(device)\n\nstyle_embedder1 = StyleEmbedder(2, style_vec_size).to(device)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d50dc65-b239-4640-9228-ec6e09961b96","_cell_guid":"8f8fe17d-533a-445a-b8d3-b17235860056","trusted":true},"cell_type":"code","source":"trainIters(encoder1, style_embedder1, decoder1, 200000, print_every=1000)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1462fe08-f991-4633-9c6a-f674aadabc4a","_cell_guid":"d597bbbc-f75e-4b8c-8a76-19c9536326ff","trusted":true},"cell_type":"markdown","source":"Evaluation"},{"metadata":{"_uuid":"9dc698ef-2101-4cb6-b599-769d7edacc9b","_cell_guid":"ef42e796-29dd-4085-a9de-116e4a67a3aa","trusted":true},"cell_type":"code","source":"def encoderStep_deleteOnly(encoder, style_embedder, sentence, style, max_length=MAX_LENGTH):\n    input_tensor = tensorFromSentence(input_lang, sentence)\n    style_tensor = tensorFromStyle(style)\n\n    input_length = input_tensor.size()[0]\n    encoder_hidden = encoder.initHidden()\n\n    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(input_tensor[ei],\n                                                 encoder_hidden)\n        encoder_outputs[ei] += encoder_output[0, 0]\n    style_embedding = style_embedder(style_tensor)\n    return torch.cat((encoder_hidden, style_embedding), 2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0960320b-521c-4707-9d87-210c2b1ab7ba","_cell_guid":"68164cc8-13cd-4731-b551-344ee1d1183b","trusted":true},"cell_type":"code","source":"ALPHA = 0.7\n\nclass Node:\n    def __init__(self, p_t, i, d_hidden, lvl, node_parent=None):\n        self.p_t = p_t\n        self.i = i\n        self.d_hidden = d_hidden\n        self.lvl = lvl\n        self.node_parent = node_parent\n        \n        self.p_sentence = self.sentenceProb()\n    \n    def prepareToDecode(self):\n        d_in = self.i.squeeze()#.detatch()\n        return d_in, self.d_hidden\n    \n    def sentenceProb(self):\n        if self.node_parent == None:\n            return self.p_t\n        return self.node_parent.sentenceProb() + self.p_t #addition because of log\n    \n    def normProb(self):\n        #Normalised probability - deprecated\n#         return 1/((self.lvl+1)**ALPHA) * self.sentenceProb()\n        #perplexity\n        return torch.exp(self.sentenceProb()) ** (-1/(self.lvl+1))\n    \n    def getToken(self):\n        return output_lang.index2word[self.i.item()]\n    \n    def getTokens(self):\n        token = [self.getToken()]\n#         print(token)\n        if(self.node_parent == None):\n            return token\n        else:\n             return self.node_parent.getTokens() + token\n#         return tokens\n    def getSentence(self):\n        return ' '.join(self.getTokens())\n# Normalize 1/num words^alpha (alpha = 0.7)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a06f252e-7ca7-4065-a964-d0fd3ea81a6e","_cell_guid":"9d4a17d4-5ef0-4440-8c1b-a178a13292ee","trusted":true},"cell_type":"code","source":"def evaluateWithoutBeamSearch(encoder, style_embedder, decoder, sentence, style, max_length=MAX_LENGTH):\n    with torch.no_grad():\n        \n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoderStep_deleteOnly(encoder, style_embedder, sentence, style)\n        \n        decoded_words = []\n\n        for di in range(max_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden)\n            \n            topv, topi = decoder_output.data.topk(1)\n            \n            \n            if topi.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            else:\n                decoded_words.append(output_lang.index2word[topi.item()])\n\n            decoder_input = topi.squeeze().detach()\n\n        return decoded_words","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7192804-c3cd-4ea8-b0d9-301aa2fbd850","_cell_guid":"5abe6029-76d3-4f9e-8cd9-92143fefa3c4","trusted":true},"cell_type":"code","source":"BEAM_WIDTH = 10\n\ndef evaluate_deleteOnly(encoder, style_embedder, decoder, sentence, style, max_length=MAX_LENGTH):\n    with torch.no_grad():    \n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoderStep_deleteOnly(encoder, style_embedder, sentence, style)\n        decoded_words = []\n\n        nodes = []\n        finished_nodes = []\n        for di in range(max_length):\n            if di == 0:\n                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n                top_ps, top_is = decoder_output.data.topk(BEAM_WIDTH)\n\n                top_ps = top_ps.view(-1)\n                top_is = top_is.view(-1)\n\n                for index in range(len(top_is)):\n                    p_t = top_ps[index]\n                    i = top_is[index]\n                    nodes.append(Node(p_t, i, decoder_hidden, di))\n\n            else:\n                prev_nodes = [x for x in nodes if x.lvl == di-1]\n                prev_nodes = sorted(prev_nodes, key=lambda x: x.p_sentence.item(), reverse=True)\n                prev_nodes = prev_nodes[:BEAM_WIDTH]\n\n                nodes = []\n                for node in prev_nodes:\n                    decoder_output, decoder_hidden = decoder(*node.prepareToDecode())\n                    top_ps, top_is = decoder_output.data.topk(BEAM_WIDTH)\n                    top_ps = top_ps.view(-1)\n                    top_is = top_is.view(-1)    \n                    \n                    for index in range(len(top_is)):\n                        p_t = top_ps[index]\n                        i = top_is[index]\n                        child_node = Node(p_t, i, decoder_hidden, di, node)\n                        \n                        if i.item() == EOS_token:\n                            finished_nodes.append(child_node)\n                        else:\n                            nodes.append(child_node)\n                            \n        final_node = sorted(finished_nodes, key=lambda x: x.p_sentence.item(), reverse=True)[0]\n        return final_node.getSentence()\nevaluate_deleteOnly(encoder1, style_embedder1, decoder1, \"the food\", 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1383f51b-bbc0-4f46-afaa-20f68f9f89fe","_cell_guid":"8d0d3846-d8d6-477e-8171-13c0fd432dfd","trusted":true},"cell_type":"code","source":"def evaluateRandomly(encoder, style_embedder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        print('style: ', pair[2])\n        \n        \n        output_words = evaluate_deleteOnly(encoder, style_embedder, decoder, pair[0], pair[2])\n        output_sentence = ' '.join(output_words)\n        \n        print('<', output_sentence)\n        print('')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa634017-1231-42ba-b555-8239109a64e4","_cell_guid":"39b57d37-131c-4d85-99c3-ef8f8b0eef17","trusted":true},"cell_type":"code","source":"evaluateRandomly(encoder1, style_embedder1, decoder1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"508c7035-4176-4258-9a69-26b5f9b7d70f","_cell_guid":"5716fcfd-6b2b-4c91-99cf-9a385d511c82","trusted":true},"cell_type":"code","source":"def DeleteOnly(sentence, style_src):\n    return evaluate_deleteOnly(encoder1, style_embedder1, decoder1, sentence, not style_src)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9befcff3-7cc3-4b04-9f0d-71fc3e3cb889","_cell_guid":"d71b68e6-0545-4c9a-8dc2-0542a79e8528","trusted":true},"cell_type":"code","source":"sentence = \"we sit down and we got some really slow and lazy service .\"\nstyle_src = 0\nDeleteOnly(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7a2343d-94ba-44a1-89f0-0d29e79d12f1","_cell_guid":"66035d98-9343-40e2-8601-9d811b723b09","trusted":true},"cell_type":"markdown","source":"### RetrieveOnly"},{"metadata":{"_uuid":"dfc47469-4916-4e23-b998-20d0d175f6e6","_cell_guid":"62e898b7-5854-4e60-9f51-89fccafa8292","trusted":true},"cell_type":"code","source":"def get_euclidean_distance(c, c2):\n    return torch.dist(get_c_embedding(encoder_c, c), get_c_embedding(encoder_c, c2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54363f80-8617-48d0-83bb-ffe967470d24","_cell_guid":"56b108a3-12c6-46ad-a3f7-0f5fb4096008","trusted":true},"cell_type":"code","source":"def RetrieveOnly(sentence, style_src):\n    opposite_dataset = d_neg if style_src else d_pos\n\n    closest_sentence = \"\"\n\n    c_src = get_c(sentence, style_src)\n\n    min_distance = -1\n    for sentence_b in opposite_dataset:\n        c_tgt = get_c(sentence_b, not style_src)\n\n        dist = get_euclidean_distance(c_src, c_tgt)\n        if min_distance == -1 or dist < min_distance:\n            min_distance = dist\n            closest_sentence = sentence_b\n\n    return closest_sentence","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9890434-35c4-43f6-bb60-488458be7894","_cell_guid":"0deaabf3-76c7-49cd-bb71-a939e43e179a","trusted":true},"cell_type":"code","source":"sentence = \"we sit down and we got some really slow and lazy service .\"\nstyle_src = 0\nRetrieveOnly(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe19ff19-3692-4e0b-8867-ea86dca4ed1c","_cell_guid":"d75a84ff-e05c-4b94-ad5b-7ab523ef8e0f","trusted":true},"cell_type":"markdown","source":"### Comparison"},{"metadata":{"_uuid":"bd327c7d-740d-4e7e-81e3-5b4a269d17bf","_cell_guid":"c4cb93f8-66a7-46a7-8c6d-70ff2a49a83c","trusted":true},"cell_type":"code","source":"sentence = \"we sit down and we got some really slow and lazy service .\"\nstyle_src = 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74db5fed-1cdd-4ce5-a491-ecba7fa52260","_cell_guid":"c460fd4f-0b44-4d09-b4f4-e638a1549950","trusted":true},"cell_type":"code","source":"TemplateBased(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f98c5aa2-abf6-40a9-adbd-c27fa154ba54","_cell_guid":"cba3ce6b-5b05-423a-9ada-11dfdde36834","trusted":true},"cell_type":"code","source":"RetrieveOnly(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae4805fe-d0a4-4dd2-873d-a7fdd31bb3aa","_cell_guid":"034c681c-7ffc-4873-8359-8dea4f2055ba","trusted":true},"cell_type":"code","source":"DeleteOnly(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4541f987-8987-4c5c-b013-4642c0bfa938","_cell_guid":"77c2eba8-989e-4a3b-abe1-b20a89ab7c8d","trusted":true},"cell_type":"code","source":"DeleteAndRetrieve(sentence, style_src)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b699ea2e-5fc8-4af4-bdb1-508d5fe0f700","_cell_guid":"4b23b75c-b8c4-43bf-ae5c-af268c792593","trusted":true},"cell_type":"markdown","source":"### Classifier"},{"metadata":{"_uuid":"5e414a13-c9d8-40e7-b0c2-515f856b4476","_cell_guid":"5abe328a-0836-4435-9201-db3225c94916","trusted":true},"cell_type":"code","source":"#Since a sentiment classifier is only a small & simple component, & is nothing new, I followed a tutorial instead of doing it 100% from scratch like above code.\n# https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6147031c-8e19-4266-962a-7da715422bcb","_cell_guid":"167f418f-7fd3-4ad6-a915-38df8e8a0a22","trusted":true},"cell_type":"code","source":"TRAIN_SPLIT_PERCENT = 0.8\nfrom fastai.text import *","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8a02c89-b5f9-4a09-a043-bf735dcb43d6","_cell_guid":"6c50bd31-feb3-4a35-8d9d-f5fb6dc2edc8","trusted":true},"cell_type":"code","source":"df = pd.DataFrame(np.random.randn(d_all['labels'].count(), 2))\nmsk = np.random.rand(len(df)) < TRAIN_SPLIT_PERCENT\ntrain = d_all[msk]\ntest = d_all[~msk]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b9c0ea7-9065-4e98-bd60-e1f16dc940fb","_cell_guid":"da7cb42a-2719-47ee-a3bc-94e4510a9dea","trusted":true},"cell_type":"code","source":"data = (TextList.from_df(train, cols='text')\n                .split_by_rand_pct(0.2)\n                .label_for_lm()  \n                .databunch(bs=48))\ndata.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e4bc6d9-619f-4836-b8f3-60a6aab6b1ad","_cell_guid":"1cced3f3-5950-4b70-bbc4-74c16d6d6b70","trusted":true},"cell_type":"code","source":"learner = language_model_learner(data, AWD_LSTM, drop_mult=0.3)\nlearner.lr_find()\n\n# we typically find the point where the slope is steepest\nlearner.recorder.plot()\n\n# Fit the model based on selected learning rate\nlearner.fit_one_cycle(5, 1e-2, moms=(0.8,0.7))\n\n# Tune a little more\nlearner.unfreeze()\nlearner.fit_one_cycle(5, 1e-3, moms=(0.8,0.7))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4bdb6337-1d4b-4be1-baa2-f684bc5a6a30","_cell_guid":"3a8c797b-ab9f-45a9-8c77-4be7eab01cb0","trusted":true},"cell_type":"code","source":"learner.save_encoder('fine_tuned_enc')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28096b2d-dde2-4abc-b5fe-f4bcc2a8af39","_cell_guid":"5ba35155-0462-4378-b622-75cbd8aa692c","trusted":true},"cell_type":"code","source":"test_datalist = TextList.from_df(test, cols='text', vocab=data.vocab)\n\ndata_clas = (TextList.from_df(train, cols='text', vocab=data.vocab)\n             .split_by_rand_pct(0.2)\n             .label_from_df(cols= 'labels')\n             .add_test(test_datalist)\n             .databunch(bs=32))\n\ndata_clas.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15e82ed4-3680-4bc5-ad69-8501c37b86ec","_cell_guid":"faacff3d-3368-40f1-b4b1-4b7227813990","trusted":true},"cell_type":"code","source":"learn_classifier = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n\n# load the encoder saved  \nlearn_classifier.load_encoder('fine_tuned_enc')\n\nlearn_classifier.freeze()\n\n# select the appropriate learning rate\nlearn_classifier.lr_find()\n\n# we typically find the point where the slope is steepest\nlearn_classifier.recorder.plot()\n\n# Fit the model based on selected learning rate\nlearn_classifier.fit_one_cycle(5, 2e-2, moms=(0.8,0.7))\n\n# Tune a little more\nlearn_classifier.freeze_to(-2)\nlearn_classifier.fit_one_cycle(5, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))\n\n# Tune a little more\nlearn_classifier.freeze_to(-3)\nlearn_classifier.fit_one_cycle(5, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))\n\nlearn_classifier.show_results()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70c5c7dd-ff60-4791-8cae-c13203ef432d","_cell_guid":"301a5fe9-ec35-476a-9820-b29d76db7fa9","trusted":true},"cell_type":"code","source":"sentence = \"we sit down and we got some really slow and lazy service .\"\nstyle_src = 0\n\ndef predict_style(sentence):\n    predicted_value = learn_classifier.predict(sentence)[0].data[0]\n    if(predicted_value > 0.5):\n        return 1\n    else:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b3ad385-1e1d-4155-8f5a-88c72024517e","_cell_guid":"60251c20-9b22-4dd5-b112-e4ca67e404e6","trusted":true},"cell_type":"code","source":"predict_style(\"bad\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"879ca6ca-8d08-4980-a7e7-62cf1fcb3070","_cell_guid":"db4e1254-f8d7-423b-9114-014f02fd212a","trusted":true},"cell_type":"markdown","source":"### Get Scores"},{"metadata":{"_uuid":"889a5ab5-f5f4-479c-a375-4ec80f23114b","_cell_guid":"e89a2627-37c4-4a01-91d0-5090d5f3871a","trusted":true},"cell_type":"code","source":"def get_scores(func, num_tests=None):\n    if(num_tests == None):\n        pos_refs = d_pos_ref\n        neg_refs = d_neg_ref\n    else:\n        pos_refs = d_pos_ref[:num_tests//2]\n        neg_refs = d_neg_ref[:num_tests//2]\n    \n    num_correct = 0\n    total = 0\n    \n    hypotheses = []\n    references = []\n    \n    for pair in pos_refs:\n        #positive dataset\n        sentence = pair[0]\n        hypothesis = func(sentence, 1)\n        reference = pair[1]\n        \n        hypotheses.append(hypothesis)\n        references.append(reference)\n        \n        predicted_style = predict_style(hypothesis)\n        actual_style = 0\n        if predicted_style == actual_style:\n            num_correct +=1\n        total +=1\n        print(\"H, R, P: \", hypothesis, reference, predicted_style)\n        \n    for pair in neg_refs:\n        #positive dataset\n        sentence = pair[0]\n        hypothesis = func(sentence, 0)\n        reference = pair[1]\n        \n        hypotheses.append(hypothesis)\n        references.append(reference)\n        \n        \n        predicted_style = predict_style(hypothesis)\n        actual_style = 1\n        if predicted_style == actual_style:\n            num_correct +=1\n        total +=1\n        print(\"H, R, P: \", hypothesis, reference, predicted_style)\n    \n    if (num_correct > 0):\n        accuracy = num_correct / total\n    else:\n        accuracy = 0\n        \n    bleu_score = get_moses_multi_bleu(hypotheses, references, True)\n    print(\"Accuracy: \", accuracy)\n    print(\"BLEU: \", bleu_score)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e31cedcc-0ec4-4c3b-9264-90104fe2d176","_cell_guid":"f6ecef91-e613-41fe-a17d-7fd76d80e392","trusted":true},"cell_type":"code","source":"get_scores(TemplateBased)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c24416c1-1e1f-4cf3-991c-0fa2840392a4","_cell_guid":"498a0bf9-7326-45d5-ada2-20348372ee67","trusted":true},"cell_type":"code","source":"get_scores(RetrieveOnly)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b2557d7-faca-42e1-908f-a6583147fb40","_cell_guid":"92a6f998-d554-428a-8247-72a25e2cacef","trusted":true},"cell_type":"code","source":"get_scores(DeleteOnly)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4acb3ade-18ee-46bf-90c9-7cabea57f0d5","_cell_guid":"36c89d59-17c5-4470-8bf9-5015b129fcdc","trusted":true},"cell_type":"code","source":"get_scores(DeleteAndRetrieve)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}